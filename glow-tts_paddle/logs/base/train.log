2023-12-06 21:22:42,073	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 32, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:23:42,652	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 32, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:24:41,146	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 32, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:25:54,557	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:27:08,342	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:27:44,796	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:28:17,567	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:28:29,959	base	INFO	Saving model and optimizer state at iteration 0 to ./logs/base/ddi_G.pth
2023-12-06 21:30:40,831	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:30:50,557	base	INFO	Saving model and optimizer state at iteration 0 to ./logs/base/ddi_G.pth
2023-12-06 21:31:49,458	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:32:02,259	base	INFO	Saving model and optimizer state at iteration 0 to ./logs/base/ddi_G.pth
2023-12-06 21:33:39,352	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 21:33:51,871	base	INFO	Saving model and optimizer state at iteration 0 to ./logs/base/ddi_G.pth
2023-12-06 22:01:29,183	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 22:02:05,698	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 22:02:17,697	base	INFO	Loaded checkpoint './logs/base/ddi_G.pth' (iteration 0)
2023-12-06 22:05:17,480	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 22:05:30,263	base	INFO	Loaded checkpoint './logs/base/ddi_G.pth' (iteration 0)
2023-12-06 22:07:01,806	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-06 22:07:13,402	base	INFO	Loaded checkpoint './logs/base/ddi_G.pth' (iteration 0)
2023-12-06 22:07:15,382	base	INFO	Train Epoch: 1 [0/12500 (0%)]	Loss: 2.922097
2023-12-06 22:07:15,383	base	INFO	[1.2334299087524414, 1.6886671781539917, 0, 5.70544330734548e-07]
2023-12-06 22:07:41,745	base	INFO	Train Epoch: 1 [160/12500 (1%)]	Loss: 2.609765
2023-12-06 22:07:41,746	base	INFO	[1.1945204734802246, 1.415244460105896, 20, 6.2759876380800285e-06]
2023-12-06 22:07:56,493	base	INFO	Train Epoch: 1 [320/12500 (3%)]	Loss: 2.202677
2023-12-06 22:07:56,494	base	INFO	[1.1490795612335205, 1.0535979270935059, 40, 1.1981430945425508e-05]
2023-12-07 10:42:40,300	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 10:42:40,300	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 10:43:47,195	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 10:43:47,195	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 10:48:40,425	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 10:48:40,425	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:00:36,184	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:00:36,184	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:01:45,822	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:01:45,822	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:03:25,626	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:03:25,627	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:04:28,107	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:04:28,107	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:05:14,891	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:05:14,891	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:06:30,861	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:06:30,861	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:07:38,636	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:07:38,636	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:10:51,127	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:10:51,127	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:13:04,128	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:13:04,129	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:15:56,962	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:15:56,963	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:19:07,025	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:19:07,026	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:22:38,149	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:22:38,150	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:24:42,465	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:24:42,466	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:25:20,339	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:25:20,340	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:27:17,983	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:27:17,984	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:28:10,459	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:28:10,459	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:28:19,455	base	INFO	Saving model and optimizer state at iteration 0 to ./logs/base/ddi_G.pdparams
2023-12-07 11:29:24,262	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:29:24,262	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:29:35,041	base	INFO	Saving model and optimizer state at iteration 0 to ./logs/base/ddi_G.pdparams
2023-12-07 11:34:26,060	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:34:26,060	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:35:02,754	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:35:02,755	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:35:35,769	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:35:35,769	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:36:21,798	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:36:21,798	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:38:21,297	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:38:21,298	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:39:00,875	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:39:00,876	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:41:33,028	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:41:33,029	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:41:46,115	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 11:42:10,353	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:42:10,354	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:42:22,089	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 11:44:02,692	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:44:02,692	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:44:12,355	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 11:46:29,560	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:46:29,561	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:46:42,610	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 11:50:43,706	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:50:43,707	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:50:55,423	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 11:52:22,448	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:52:22,448	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:52:37,099	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 11:57:51,411	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:57:51,412	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:58:19,783	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 11:58:19,784	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 11:58:35,470	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 12:04:27,956	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 12:04:27,956	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 12:04:40,175	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 12:05:11,878	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 12:05:11,879	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 12:05:27,298	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 12:05:30,443	base	INFO	Train Epoch: 1 [0/12500 (0%)]	Loss: 4.235771
2023-12-07 12:05:30,443	base	INFO	[2.0457682609558105, 2.19000244140625, 0, 5.70544330734548e-07]
2023-12-07 12:06:49,780	base	INFO	{'train': {'use_cuda': True, 'log_interval': 20, 'seed': 1234, 'epochs': 10000, 'learning_rate': 1.0, 'betas': [0.9, 0.98], 'eps': 1e-09, 'warmup_steps': 4000, 'scheduler': 'noam', 'batch_size': 8, 'ddi': True, 'fp16_run': True}, 'data': {'load_mel_from_disk': False, 'training_files': 'filelists/ljs_audio_text_train_filelist.txt', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt', 'text_cleaners': ['english_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True, 'cmudict_path': 'data/cmu_dictionary'}, 'model': {'hidden_channels': 192, 'filter_channels': 768, 'filter_channels_dp': 256, 'kernel_size': 3, 'p_dropout': 0.1, 'n_blocks_dec': 12, 'n_layers_enc': 6, 'n_heads': 2, 'p_dropout_dec': 0.05, 'dilation_rate': 1, 'kernel_size_dec': 5, 'n_block_layers': 4, 'n_sqz': 2, 'prenet': True, 'mean_only': True, 'hidden_channels_enc': 192, 'hidden_channels_dec': 192, 'window_size': 4}, 'model_dir': './logs/base'}
2023-12-07 12:06:49,780	base	WARNING	/home1/zhaoyh/paddlemodel/glow-tts_paddle is not a git repository, therefore hash value comparison will be ignored.
2023-12-07 12:07:03,467	base	INFO	Loaded checkpoint './logs/base/ddi_G.pdparams' (iteration 0)
2023-12-07 12:07:06,888	base	INFO	Train Epoch: 1 [0/12500 (0%)]	Loss: 4.650084
2023-12-07 12:07:06,889	base	INFO	[2.0211563110351562, 2.628927230834961, 0, 5.70544330734548e-07]
2023-12-07 12:07:22,988	base	INFO	Train Epoch: 1 [160/12500 (1%)]	Loss: 3.807311
2023-12-07 12:07:22,998	base	INFO	[1.5252737998962402, 2.2820370197296143, 20, 6.2759876380800285e-06]
2023-12-07 12:07:39,408	base	INFO	Train Epoch: 1 [320/12500 (3%)]	Loss: 3.444171
2023-12-07 12:07:39,410	base	INFO	[1.2521202564239502, 2.1920511722564697, 40, 1.1981430945425508e-05]
2023-12-07 12:07:57,405	base	INFO	Train Epoch: 1 [480/12500 (4%)]	Loss: 2.935537
2023-12-07 12:07:57,411	base	INFO	[1.1268104314804077, 1.808726191520691, 60, 1.768687425277099e-05]
2023-12-07 12:08:15,025	base	INFO	Train Epoch: 1 [640/12500 (5%)]	Loss: 2.481925
2023-12-07 12:08:15,038	base	INFO	[1.0271269083023071, 1.4547984600067139, 80, 2.339231756011647e-05]
2023-12-07 12:08:31,630	base	INFO	Train Epoch: 1 [800/12500 (6%)]	Loss: 2.435697
2023-12-07 12:08:31,639	base	INFO	[0.9336587190628052, 1.5020384788513184, 100, 2.909776086746195e-05]
2023-12-07 12:08:48,279	base	INFO	Train Epoch: 1 [960/12500 (8%)]	Loss: 2.270971
2023-12-07 12:08:48,290	base	INFO	[0.8557525873184204, 1.4152179956436157, 120, 3.480320417480743e-05]
2023-12-07 12:09:04,868	base	INFO	Train Epoch: 1 [1120/12500 (9%)]	Loss: 1.986065
2023-12-07 12:09:04,877	base	INFO	[0.7889237403869629, 1.197141408920288, 140, 4.0508647482152914e-05]
2023-12-07 12:09:21,094	base	INFO	Train Epoch: 1 [1280/12500 (10%)]	Loss: 1.984089
2023-12-07 12:09:21,102	base	INFO	[0.7279968857765198, 1.2560923099517822, 160, 4.621409078949839e-05]
2023-12-07 12:09:37,642	base	INFO	Train Epoch: 1 [1440/12500 (12%)]	Loss: 2.044375
2023-12-07 12:09:37,651	base	INFO	[0.6858767867088318, 1.358498454093933, 180, 5.1919534096843875e-05]
2023-12-07 12:09:54,127	base	INFO	Train Epoch: 1 [1600/12500 (13%)]	Loss: 1.839487
2023-12-07 12:09:54,137	base	INFO	[0.6643027067184448, 1.1751841306686401, 200, 5.762497740418935e-05]
2023-12-07 12:10:11,419	base	INFO	Train Epoch: 1 [1760/12500 (14%)]	Loss: 1.767751
2023-12-07 12:10:11,428	base	INFO	[0.6122206449508667, 1.1555304527282715, 220, 6.333042071153483e-05]
2023-12-07 12:10:28,748	base	INFO	Train Epoch: 1 [1920/12500 (15%)]	Loss: 1.789344
2023-12-07 12:10:28,749	base	INFO	[0.5862738490104675, 1.2030701637268066, 240, 6.90358640188803e-05]
2023-12-07 12:10:45,100	base	INFO	Train Epoch: 1 [2080/12500 (17%)]	Loss: 1.501736
2023-12-07 12:10:45,102	base	INFO	[0.5463417768478394, 0.9553940892219543, 260, 7.474130732622578e-05]
2023-12-07 12:11:01,311	base	INFO	Train Epoch: 1 [2240/12500 (18%)]	Loss: 1.486389
2023-12-07 12:11:01,313	base	INFO	[0.5335654020309448, 0.95282381772995, 280, 8.044675063357127e-05]
2023-12-07 12:11:17,865	base	INFO	Train Epoch: 1 [2400/12500 (19%)]	Loss: 1.464515
2023-12-07 12:11:17,867	base	INFO	[0.519273042678833, 0.9452419877052307, 300, 8.615219394091675e-05]
2023-12-07 12:11:34,284	base	INFO	Train Epoch: 1 [2560/12500 (20%)]	Loss: 1.524279
2023-12-07 12:11:34,286	base	INFO	[0.500907301902771, 1.0233720541000366, 320, 9.185763724826224e-05]
2023-12-07 12:11:50,323	base	INFO	Train Epoch: 1 [2720/12500 (22%)]	Loss: 1.483770
2023-12-07 12:11:50,329	base	INFO	[0.5031837224960327, 0.9805861711502075, 340, 9.75630805556077e-05]
2023-12-07 12:12:07,341	base	INFO	Train Epoch: 1 [2880/12500 (23%)]	Loss: 1.525248
2023-12-07 12:12:07,352	base	INFO	[0.4835212230682373, 1.04172682762146, 360, 0.0001032685238629532]
2023-12-07 12:12:23,445	base	INFO	Train Epoch: 1 [3040/12500 (24%)]	Loss: 1.498870
2023-12-07 12:12:23,453	base	INFO	[0.46249550580978394, 1.0363746881484985, 380, 0.00010897396717029867]
2023-12-07 12:12:39,668	base	INFO	Train Epoch: 1 [3200/12500 (26%)]	Loss: 1.524249
2023-12-07 12:12:39,676	base	INFO	[0.4754936397075653, 1.0487555265426636, 400, 0.00011467941047764416]
2023-12-07 12:12:55,932	base	INFO	Train Epoch: 1 [3360/12500 (27%)]	Loss: 1.464485
2023-12-07 12:12:55,943	base	INFO	[0.4362325370311737, 1.0282526016235352, 420, 0.00012038485378498964]
2023-12-07 12:13:13,069	base	INFO	Train Epoch: 1 [3520/12500 (28%)]	Loss: 1.387624
2023-12-07 12:13:13,070	base	INFO	[0.44089359045028687, 0.9467299580574036, 440, 0.00012609029709233512]
2023-12-07 12:13:29,524	base	INFO	Train Epoch: 1 [3680/12500 (29%)]	Loss: 1.433891
2023-12-07 12:13:29,525	base	INFO	[0.42372703552246094, 1.0101641416549683, 460, 0.0001317957403996806]
2023-12-07 12:13:46,216	base	INFO	Train Epoch: 1 [3840/12500 (31%)]	Loss: 1.395423
2023-12-07 12:13:46,218	base	INFO	[0.42225706577301025, 0.973166286945343, 480, 0.00013750118370702607]
2023-12-07 12:14:03,003	base	INFO	Train Epoch: 1 [4000/12500 (32%)]	Loss: 1.369217
2023-12-07 12:14:03,007	base	INFO	[0.42248043417930603, 0.9467366933822632, 500, 0.00014320662701437155]
2023-12-07 12:14:20,368	base	INFO	Train Epoch: 1 [4160/12500 (33%)]	Loss: 1.308709
2023-12-07 12:14:20,371	base	INFO	[0.39386850595474243, 0.9148406386375427, 520, 0.00014891207032171705]
2023-12-07 12:14:36,870	base	INFO	Train Epoch: 1 [4320/12500 (35%)]	Loss: 1.393479
2023-12-07 12:14:36,875	base	INFO	[0.40321969985961914, 0.9902592301368713, 540, 0.00015461751362906253]
2023-12-07 12:14:53,633	base	INFO	Train Epoch: 1 [4480/12500 (36%)]	Loss: 1.385720
2023-12-07 12:14:53,635	base	INFO	[0.3826946020126343, 1.0030250549316406, 560, 0.00016032295693640798]
2023-12-07 12:15:10,187	base	INFO	Train Epoch: 1 [4640/12500 (37%)]	Loss: 1.358161
2023-12-07 12:15:10,190	base	INFO	[0.3860563039779663, 0.9721043109893799, 580, 0.00016602840024375348]
2023-12-07 12:15:26,549	base	INFO	Train Epoch: 1 [4800/12500 (38%)]	Loss: 1.309385
2023-12-07 12:15:26,554	base	INFO	[0.374692440032959, 0.9346920847892761, 600, 0.00017173384355109896]
2023-12-07 12:15:43,729	base	INFO	Train Epoch: 1 [4960/12500 (40%)]	Loss: 1.223339
2023-12-07 12:15:43,738	base	INFO	[0.38139158487319946, 0.841947615146637, 620, 0.00017743928685844446]
2023-12-07 12:16:00,996	base	INFO	Train Epoch: 1 [5120/12500 (41%)]	Loss: 1.298080
2023-12-07 12:16:00,997	base	INFO	[0.36414164304733276, 0.9339383840560913, 640, 0.0001831447301657899]
2023-12-07 12:16:18,409	base	INFO	Train Epoch: 1 [5280/12500 (42%)]	Loss: 1.283528
2023-12-07 12:16:18,411	base	INFO	[0.34802162647247314, 0.9355061054229736, 660, 0.0001888501734731354]
2023-12-07 12:16:34,889	base	INFO	Train Epoch: 1 [5440/12500 (44%)]	Loss: 1.289743
2023-12-07 12:16:34,892	base	INFO	[0.35044920444488525, 0.939293384552002, 680, 0.0001945556167804809]
2023-12-07 12:16:51,670	base	INFO	Train Epoch: 1 [5600/12500 (45%)]	Loss: 1.264002
2023-12-07 12:16:51,673	base	INFO	[0.33475619554519653, 0.9292460680007935, 700, 0.00020026106008782637]
2023-12-07 12:17:07,950	base	INFO	Train Epoch: 1 [5760/12500 (46%)]	Loss: 1.222491
2023-12-07 12:17:07,952	base	INFO	[0.34424149990081787, 0.8782498240470886, 720, 0.00020596650339517185]
2023-12-07 12:17:24,804	base	INFO	Train Epoch: 1 [5920/12500 (47%)]	Loss: 1.357552
2023-12-07 12:17:24,813	base	INFO	[0.33465635776519775, 1.0228960514068604, 740, 0.00021167194670251732]
2023-12-07 12:17:41,506	base	INFO	Train Epoch: 1 [6080/12500 (49%)]	Loss: 1.170422
2023-12-07 12:17:41,508	base	INFO	[0.34519141912460327, 0.8252301812171936, 760, 0.0002173773900098628]
2023-12-07 12:17:58,078	base	INFO	Train Epoch: 1 [6240/12500 (50%)]	Loss: 1.287709
2023-12-07 12:17:58,087	base	INFO	[0.33550500869750977, 0.9522043466567993, 780, 0.0002230828333172083]
2023-12-07 12:18:15,234	base	INFO	Train Epoch: 1 [6400/12500 (51%)]	Loss: 1.179790
2023-12-07 12:18:15,247	base	INFO	[0.33343619108200073, 0.846354067325592, 800, 0.00022878827662455375]
2023-12-07 12:18:32,084	base	INFO	Train Epoch: 1 [6560/12500 (52%)]	Loss: 1.293061
2023-12-07 12:18:32,094	base	INFO	[0.3436286449432373, 0.9494324326515198, 820, 0.00023449371993189923]
2023-12-07 12:18:49,116	base	INFO	Train Epoch: 1 [6720/12500 (54%)]	Loss: 1.279767
2023-12-07 12:18:49,118	base	INFO	[0.33077478408813477, 0.9489923119544983, 840, 0.00024019916323924473]
2023-12-07 12:19:05,294	base	INFO	Train Epoch: 1 [6880/12500 (55%)]	Loss: 1.186894
2023-12-07 12:19:05,296	base	INFO	[0.31887173652648926, 0.868022084236145, 860, 0.0002459046065465902]
2023-12-07 12:19:21,845	base	INFO	Train Epoch: 1 [7040/12500 (56%)]	Loss: 1.136731
2023-12-07 12:19:21,848	base	INFO	[0.31863313913345337, 0.8180980086326599, 880, 0.0002516100498539357]
2023-12-07 12:19:38,283	base	INFO	Train Epoch: 1 [7200/12500 (58%)]	Loss: 1.231774
2023-12-07 12:19:38,285	base	INFO	[0.3027670383453369, 0.9290071725845337, 900, 0.00025731549316128117]
2023-12-07 12:19:54,615	base	INFO	Train Epoch: 1 [7360/12500 (59%)]	Loss: 1.215124
2023-12-07 12:19:54,619	base	INFO	[0.30178970098495483, 0.9133338928222656, 920, 0.00026302093646862664]
2023-12-07 12:20:10,915	base	INFO	Train Epoch: 1 [7520/12500 (60%)]	Loss: 1.169607
2023-12-07 12:20:10,918	base	INFO	[0.29515427350997925, 0.8744526505470276, 940, 0.0002687263797759721]
2023-12-07 12:20:28,149	base	INFO	Train Epoch: 1 [7680/12500 (61%)]	Loss: 1.181447
2023-12-07 12:20:28,152	base	INFO	[0.30168741941452026, 0.8797594308853149, 960, 0.0002744318230833176]
2023-12-07 12:20:44,230	base	INFO	Train Epoch: 1 [7840/12500 (63%)]	Loss: 1.182100
2023-12-07 12:20:44,240	base	INFO	[0.30810797214508057, 0.8739920258522034, 980, 0.0002801372663906631]
2023-12-07 12:21:01,054	base	INFO	Train Epoch: 1 [8000/12500 (64%)]	Loss: 1.210490
2023-12-07 12:21:01,056	base	INFO	[0.291093647480011, 0.9193961024284363, 1000, 0.00028584270969800855]
2023-12-07 12:21:16,933	base	INFO	Train Epoch: 1 [8160/12500 (65%)]	Loss: 1.247203
2023-12-07 12:21:16,944	base	INFO	[0.2885627746582031, 0.9586406946182251, 1020, 0.00029154815300535403]
2023-12-07 12:21:33,492	base	INFO	Train Epoch: 1 [8320/12500 (67%)]	Loss: 1.207265
2023-12-07 12:21:33,494	base	INFO	[0.2875014543533325, 0.9197635650634766, 1040, 0.00029725359631269956]
2023-12-07 12:21:49,841	base	INFO	Train Epoch: 1 [8480/12500 (68%)]	Loss: 1.214812
2023-12-07 12:21:49,842	base	INFO	[0.28378039598464966, 0.9310319423675537, 1060, 0.00030295903962004504]
2023-12-07 12:22:05,999	base	INFO	Train Epoch: 1 [8640/12500 (69%)]	Loss: 1.199805
2023-12-07 12:22:06,002	base	INFO	[0.2937809228897095, 0.9060235619544983, 1080, 0.00030866448292739046]
2023-12-07 12:22:23,034	base	INFO	Train Epoch: 1 [8800/12500 (70%)]	Loss: 1.220555
2023-12-07 12:22:23,038	base	INFO	[0.2862522602081299, 0.9343023896217346, 1100, 0.000314369926234736]
2023-12-07 12:22:39,125	base	INFO	Train Epoch: 1 [8960/12500 (72%)]	Loss: 1.223181
2023-12-07 12:22:39,127	base	INFO	[0.2795411944389343, 0.9436399340629578, 1120, 0.00032007536954208147]
2023-12-07 12:22:55,423	base	INFO	Train Epoch: 1 [9120/12500 (73%)]	Loss: 1.212165
2023-12-07 12:22:55,425	base	INFO	[0.2781149744987488, 0.9340503811836243, 1140, 0.0003257808128494269]
2023-12-07 12:23:11,547	base	INFO	Train Epoch: 1 [9280/12500 (74%)]	Loss: 1.225074
2023-12-07 12:23:11,551	base	INFO	[0.2725147604942322, 0.952559232711792, 1160, 0.0003314862561567724]
2023-12-07 12:23:28,041	base	INFO	Train Epoch: 1 [9440/12500 (76%)]	Loss: 1.273341
2023-12-07 12:23:28,049	base	INFO	[0.2646412253379822, 1.0087000131607056, 1180, 0.0003371916994641179]
2023-12-07 12:23:44,388	base	INFO	Train Epoch: 1 [9600/12500 (77%)]	Loss: 1.239164
2023-12-07 12:23:44,398	base	INFO	[0.2622429132461548, 0.9769209027290344, 1200, 0.0003428971427714634]
2023-12-07 12:24:00,628	base	INFO	Train Epoch: 1 [9760/12500 (78%)]	Loss: 1.235896
2023-12-07 12:24:00,638	base	INFO	[0.2668313980102539, 0.969064474105835, 1220, 0.00034860258607880885]
2023-12-07 12:24:17,566	base	INFO	Train Epoch: 1 [9920/12500 (79%)]	Loss: 1.195105
2023-12-07 12:24:17,568	base	INFO	[0.26732784509658813, 0.9277773499488831, 1240, 0.00035430802938615433]
2023-12-07 12:24:34,816	base	INFO	Train Epoch: 1 [10080/12500 (81%)]	Loss: 1.198267
2023-12-07 12:24:34,818	base	INFO	[0.2522481679916382, 0.9460184574127197, 1260, 0.0003600134726934998]
2023-12-07 12:24:51,070	base	INFO	Train Epoch: 1 [10240/12500 (82%)]	Loss: 1.284866
2023-12-07 12:24:51,072	base	INFO	[0.26017165184020996, 1.024694800376892, 1280, 0.0003657189160008453]
2023-12-07 12:25:07,119	base	INFO	Train Epoch: 1 [10400/12500 (83%)]	Loss: 1.268617
2023-12-07 12:25:07,122	base	INFO	[0.26321542263031006, 1.0054014921188354, 1300, 0.00037142435930819076]
2023-12-07 12:25:23,185	base	INFO	Train Epoch: 1 [10560/12500 (85%)]	Loss: 1.285466
2023-12-07 12:25:23,188	base	INFO	[0.2614173889160156, 1.0240483283996582, 1320, 0.0003771298026155363]
2023-12-07 12:25:39,471	base	INFO	Train Epoch: 1 [10720/12500 (86%)]	Loss: 1.261435
2023-12-07 12:25:39,475	base	INFO	[0.2524300217628479, 1.0090051889419556, 1340, 0.0003828352459228817]
2023-12-07 12:25:55,631	base	INFO	Train Epoch: 1 [10880/12500 (87%)]	Loss: 1.286417
2023-12-07 12:25:55,634	base	INFO	[0.2457483410835266, 1.0406688451766968, 1360, 0.00038854068923022724]
2023-12-07 12:26:12,052	base	INFO	Train Epoch: 1 [11040/12500 (88%)]	Loss: 1.197764
2023-12-07 12:26:12,062	base	INFO	[0.24049538373947144, 0.957268476486206, 1380, 0.0003942461325375727]
2023-12-07 12:26:29,162	base	INFO	Train Epoch: 1 [11200/12500 (90%)]	Loss: 1.285132
2023-12-07 12:26:29,164	base	INFO	[0.24260449409484863, 1.0425279140472412, 1400, 0.00039995157584491814]
2023-12-07 12:26:45,165	base	INFO	Train Epoch: 1 [11360/12500 (91%)]	Loss: 1.338105
2023-12-07 12:26:45,173	base	INFO	[0.24489808082580566, 1.0932068824768066, 1420, 0.0004056570191522637]
2023-12-07 12:27:02,017	base	INFO	Train Epoch: 1 [11520/12500 (92%)]	Loss: 1.323522
2023-12-07 12:27:02,018	base	INFO	[0.24639087915420532, 1.0771311521530151, 1440, 0.00041136246245960915]
2023-12-07 12:27:18,270	base	INFO	Train Epoch: 1 [11680/12500 (93%)]	Loss: 1.289778
2023-12-07 12:27:18,273	base	INFO	[0.25505387783050537, 1.0347236394882202, 1460, 0.0004170679057669546]
2023-12-07 12:27:34,620	base	INFO	Train Epoch: 1 [11840/12500 (95%)]	Loss: 1.366812
2023-12-07 12:27:34,623	base	INFO	[0.24203228950500488, 1.1247795820236206, 1480, 0.0004227733490743001]
2023-12-07 12:27:50,901	base	INFO	Train Epoch: 1 [12000/12500 (96%)]	Loss: 1.317241
2023-12-07 12:27:50,903	base	INFO	[0.2326703667640686, 1.0845705270767212, 1500, 0.0004284787923816456]
2023-12-07 12:28:06,996	base	INFO	Train Epoch: 1 [12160/12500 (97%)]	Loss: 1.313079
2023-12-07 12:28:06,998	base	INFO	[0.22398394346237183, 1.0890953540802002, 1520, 0.000434184235688991]
2023-12-07 12:28:23,067	base	INFO	Train Epoch: 1 [12320/12500 (99%)]	Loss: 1.305817
2023-12-07 12:28:23,077	base	INFO	[0.22443419694900513, 1.0813831090927124, 1540, 0.00043988967899633654]
2023-12-07 12:28:40,071	base	INFO	Train Epoch: 1 [12480/12500 (100%)]	Loss: 1.301039
2023-12-07 12:28:40,081	base	INFO	[0.22556829452514648, 1.0754706859588623, 1560, 0.000445595122303682]
2023-12-07 12:28:41,303	base	INFO	====> Epoch: 1
2023-12-07 12:28:41,887	base	INFO	Eval Epoch: 1 [0/100 (0%)]	Loss: 2.205594
2023-12-07 12:28:41,887	base	INFO	[0.21717792749404907, 1.9884157180786133]
2023-12-07 12:28:44,849	base	INFO	====> Epoch: 1
2023-12-07 12:28:44,850	base	INFO	Saving model and optimizer state at iteration 1 to ./logs/base/G_1.pdparams
2023-12-07 12:28:47,503	base	INFO	Train Epoch: 2 [0/12500 (0%)]	Loss: 1.431267
2023-12-07 12:28:47,503	base	INFO	[0.23745232820510864, 1.1938151121139526, 1562, 0.0004461656666344166]
2023-12-07 12:29:04,053	base	INFO	Train Epoch: 2 [160/12500 (1%)]	Loss: 1.367261
2023-12-07 12:29:04,063	base	INFO	[0.22830289602279663, 1.1389585733413696, 1582, 0.00045187110994176203]
2023-12-07 12:29:20,906	base	INFO	Train Epoch: 2 [320/12500 (3%)]	Loss: 1.310107
2023-12-07 12:29:20,916	base	INFO	[0.2148723602294922, 1.0952342748641968, 1602, 0.0004575765532491075]
2023-12-07 12:29:37,371	base	INFO	Train Epoch: 2 [480/12500 (4%)]	Loss: 1.374339
2023-12-07 12:29:37,374	base	INFO	[0.23580628633499146, 1.138533115386963, 1622, 0.00046328199655645304]
2023-12-07 12:29:53,407	base	INFO	Train Epoch: 2 [640/12500 (5%)]	Loss: 1.351950
2023-12-07 12:29:53,410	base	INFO	[0.23348265886306763, 1.1184678077697754, 1642, 0.00046898743986379846]
2023-12-07 12:30:09,560	base	INFO	Train Epoch: 2 [800/12500 (6%)]	Loss: 1.345740
2023-12-07 12:30:09,563	base	INFO	[0.21269071102142334, 1.1330488920211792, 1662, 0.00047469288317114394]
2023-12-07 12:30:25,607	base	INFO	Train Epoch: 2 [960/12500 (8%)]	Loss: 1.355072
2023-12-07 12:30:25,609	base	INFO	[0.2132643461227417, 1.1418076753616333, 1682, 0.00048039832647848947]
2023-12-07 12:30:42,377	base	INFO	Train Epoch: 2 [1120/12500 (9%)]	Loss: 1.376325
2023-12-07 12:30:42,382	base	INFO	[0.22208571434020996, 1.1542388200759888, 1702, 0.00048610376978583495]
2023-12-07 12:30:58,722	base	INFO	Train Epoch: 2 [1280/12500 (10%)]	Loss: 1.427229
2023-12-07 12:30:58,725	base	INFO	[0.21372443437576294, 1.213504433631897, 1722, 0.0004918092130931804]
2023-12-07 12:31:14,616	base	INFO	Train Epoch: 2 [1440/12500 (12%)]	Loss: 1.358253
2023-12-07 12:31:14,625	base	INFO	[0.21332257986068726, 1.1449300050735474, 1742, 0.0004975146564005258]
2023-12-07 12:31:30,483	base	INFO	Train Epoch: 2 [1600/12500 (13%)]	Loss: 1.411144
2023-12-07 12:31:30,491	base	INFO	[0.20822399854660034, 1.2029203176498413, 1762, 0.0005032200997078714]
2023-12-07 12:31:46,789	base	INFO	Train Epoch: 2 [1760/12500 (14%)]	Loss: 1.335154
2023-12-07 12:31:46,792	base	INFO	[0.2018330693244934, 1.1333205699920654, 1782, 0.0005089255430152168]
2023-12-07 12:32:02,647	base	INFO	Train Epoch: 2 [1920/12500 (15%)]	Loss: 1.352116
2023-12-07 12:32:02,659	base	INFO	[0.21003228425979614, 1.142084002494812, 1802, 0.0005146309863225623]
2023-12-07 12:32:19,184	base	INFO	Train Epoch: 2 [2080/12500 (17%)]	Loss: 1.450536
2023-12-07 12:32:19,185	base	INFO	[0.19769352674484253, 1.2528423070907593, 1822, 0.0005203364296299079]
2023-12-07 12:32:36,420	base	INFO	Train Epoch: 2 [2240/12500 (18%)]	Loss: 1.355532
2023-12-07 12:32:36,423	base	INFO	[0.2045636773109436, 1.1509679555892944, 1842, 0.0005260418729372533]
2023-12-07 12:32:52,621	base	INFO	Train Epoch: 2 [2400/12500 (19%)]	Loss: 1.315262
2023-12-07 12:32:52,624	base	INFO	[0.20300781726837158, 1.1122541427612305, 1862, 0.0005317473162445988]
2023-12-07 12:33:08,867	base	INFO	Train Epoch: 2 [2560/12500 (20%)]	Loss: 1.385756
2023-12-07 12:33:08,869	base	INFO	[0.21244031190872192, 1.173315167427063, 1882, 0.0005374527595519442]
2023-12-07 12:33:24,898	base	INFO	Train Epoch: 2 [2720/12500 (22%)]	Loss: 1.418937
2023-12-07 12:33:24,900	base	INFO	[0.20301711559295654, 1.2159196138381958, 1902, 0.0005431582028592897]
2023-12-07 12:33:40,976	base	INFO	Train Epoch: 2 [2880/12500 (23%)]	Loss: 1.371293
2023-12-07 12:33:40,979	base	INFO	[0.20775634050369263, 1.1635366678237915, 1922, 0.0005488636461666352]
2023-12-07 12:33:57,264	base	INFO	Train Epoch: 2 [3040/12500 (24%)]	Loss: 1.420072
2023-12-07 12:33:57,268	base	INFO	[0.20072948932647705, 1.2193421125411987, 1942, 0.0005545690894739807]
2023-12-07 12:34:13,446	base	INFO	Train Epoch: 2 [3200/12500 (26%)]	Loss: 1.425189
2023-12-07 12:34:13,455	base	INFO	[0.21983379125595093, 1.205355167388916, 1962, 0.0005602745327813261]
2023-12-07 12:34:29,050	base	INFO	Train Epoch: 2 [3360/12500 (27%)]	Loss: 1.325123
2023-12-07 12:34:29,057	base	INFO	[0.20139479637145996, 1.1237282752990723, 1982, 0.0005659799760886717]
2023-12-07 12:34:46,040	base	INFO	Train Epoch: 2 [3520/12500 (28%)]	Loss: 1.372871
2023-12-07 12:34:46,049	base	INFO	[0.20570915937423706, 1.167161464691162, 2002, 0.0005716854193960171]
2023-12-07 12:35:02,569	base	INFO	Train Epoch: 2 [3680/12500 (29%)]	Loss: 1.286576
2023-12-07 12:35:02,570	base	INFO	[0.19067394733428955, 1.0959022045135498, 2022, 0.0005773908627033626]
2023-12-07 12:35:18,972	base	INFO	Train Epoch: 2 [3840/12500 (31%)]	Loss: 1.371988
2023-12-07 12:35:18,974	base	INFO	[0.19809019565582275, 1.1738982200622559, 2042, 0.0005830963060107081]
2023-12-07 12:35:35,127	base	INFO	Train Epoch: 2 [4000/12500 (32%)]	Loss: 1.318871
2023-12-07 12:35:35,130	base	INFO	[0.20771557092666626, 1.1111550331115723, 2062, 0.0005888017493180535]
2023-12-07 12:35:50,862	base	INFO	Train Epoch: 2 [4160/12500 (33%)]	Loss: 1.338059
2023-12-07 12:35:50,865	base	INFO	[0.18426257371902466, 1.1537967920303345, 2082, 0.0005945071926253991]
2023-12-07 12:36:06,882	base	INFO	Train Epoch: 2 [4320/12500 (35%)]	Loss: 1.288890
2023-12-07 12:36:06,886	base	INFO	[0.196613609790802, 1.0922765731811523, 2102, 0.0006002126359327445]
2023-12-07 12:36:23,119	base	INFO	Train Epoch: 2 [4480/12500 (36%)]	Loss: 1.393260
2023-12-07 12:36:23,127	base	INFO	[0.1836807131767273, 1.2095798254013062, 2122, 0.0006059180792400901]
2023-12-07 12:36:40,484	base	INFO	Train Epoch: 2 [4640/12500 (37%)]	Loss: 1.367253
2023-12-07 12:36:40,488	base	INFO	[0.19331687688827515, 1.173936128616333, 2142, 0.0006116235225474355]
2023-12-07 12:36:56,400	base	INFO	Train Epoch: 2 [4800/12500 (38%)]	Loss: 1.329637
2023-12-07 12:36:56,408	base	INFO	[0.18835991621017456, 1.1412770748138428, 2162, 0.0006173289658547809]
2023-12-07 12:37:12,809	base	INFO	Train Epoch: 2 [4960/12500 (40%)]	Loss: 1.333697
2023-12-07 12:37:12,818	base	INFO	[0.19627982378005981, 1.1374175548553467, 2182, 0.0006230344091621266]
2023-12-07 12:37:28,721	base	INFO	Train Epoch: 2 [5120/12500 (41%)]	Loss: 1.395406
2023-12-07 12:37:28,730	base	INFO	[0.18490654230117798, 1.2104992866516113, 2202, 0.000628739852469472]
2023-12-07 12:37:45,205	base	INFO	Train Epoch: 2 [5280/12500 (42%)]	Loss: 1.356417
2023-12-07 12:37:45,206	base	INFO	[0.17751574516296387, 1.1789016723632812, 2222, 0.0006344452957768174]
2023-12-07 12:38:01,415	base	INFO	Train Epoch: 2 [5440/12500 (44%)]	Loss: 1.374729
2023-12-07 12:38:01,416	base	INFO	[0.18465828895568848, 1.1900711059570312, 2242, 0.0006401507390841629]
2023-12-07 12:38:17,345	base	INFO	Train Epoch: 2 [5600/12500 (45%)]	Loss: 1.268908
2023-12-07 12:38:17,348	base	INFO	[0.16656434535980225, 1.102344036102295, 2262, 0.0006458561823915084]
2023-12-07 12:38:33,604	base	INFO	Train Epoch: 2 [5760/12500 (46%)]	Loss: 1.252016
2023-12-07 12:38:33,605	base	INFO	[0.17877733707427979, 1.0732390880584717, 2282, 0.0006515616256988538]
2023-12-07 12:38:50,909	base	INFO	Train Epoch: 2 [5920/12500 (47%)]	Loss: 1.383615
2023-12-07 12:38:50,912	base	INFO	[0.1753031611442566, 1.2083123922348022, 2302, 0.0006572670690061994]
2023-12-07 12:39:07,175	base	INFO	Train Epoch: 2 [6080/12500 (49%)]	Loss: 1.293245
2023-12-07 12:39:07,178	base	INFO	[0.1914229393005371, 1.1018218994140625, 2322, 0.0006629725123135448]
2023-12-07 12:39:23,168	base	INFO	Train Epoch: 2 [6240/12500 (50%)]	Loss: 1.344116
2023-12-07 12:39:23,177	base	INFO	[0.18350470066070557, 1.1606115102767944, 2342, 0.0006686779556208903]
2023-12-07 12:39:39,016	base	INFO	Train Epoch: 2 [6400/12500 (51%)]	Loss: 1.316199
2023-12-07 12:39:39,025	base	INFO	[0.1878035068511963, 1.128395915031433, 2362, 0.0006743833989282358]
2023-12-07 12:39:55,119	base	INFO	Train Epoch: 2 [6560/12500 (52%)]	Loss: 1.383919
2023-12-07 12:39:55,128	base	INFO	[0.196091890335083, 1.1878271102905273, 2382, 0.0006800888422355812]
2023-12-07 12:40:11,225	base	INFO	Train Epoch: 2 [6720/12500 (54%)]	Loss: 1.333017
2023-12-07 12:40:11,234	base	INFO	[0.19045084714889526, 1.1425658464431763, 2402, 0.0006857942855429267]
2023-12-07 12:40:27,720	base	INFO	Train Epoch: 2 [6880/12500 (55%)]	Loss: 1.285462
2023-12-07 12:40:27,722	base	INFO	[0.17545926570892334, 1.1100022792816162, 2422, 0.0006914997288502723]
2023-12-07 12:40:44,897	base	INFO	Train Epoch: 2 [7040/12500 (56%)]	Loss: 1.310389
2023-12-07 12:40:44,898	base	INFO	[0.17796319723129272, 1.132426142692566, 2442, 0.0006972051721576177]
2023-12-07 12:41:01,017	base	INFO	Train Epoch: 2 [7200/12500 (58%)]	Loss: 1.280015
2023-12-07 12:41:01,020	base	INFO	[0.16509360074996948, 1.1149210929870605, 2462, 0.0007029106154649631]
2023-12-07 12:41:17,514	base	INFO	Train Epoch: 2 [7360/12500 (59%)]	Loss: 1.364791
2023-12-07 12:41:17,516	base	INFO	[0.1749783158302307, 1.1898128986358643, 2482, 0.0007086160587723087]
2023-12-07 12:41:33,868	base	INFO	Train Epoch: 2 [7520/12500 (60%)]	Loss: 1.277224
2023-12-07 12:41:33,870	base	INFO	[0.16501128673553467, 1.1122126579284668, 2502, 0.0007143215020796542]
2023-12-07 12:41:49,924	base	INFO	Train Epoch: 2 [7680/12500 (61%)]	Loss: 1.290679
2023-12-07 12:41:49,928	base	INFO	[0.17205768823623657, 1.1186213493347168, 2522, 0.0007200269453869996]
2023-12-07 12:42:06,193	base	INFO	Train Epoch: 2 [7840/12500 (63%)]	Loss: 1.287371
2023-12-07 12:42:06,197	base	INFO	[0.18186509609222412, 1.1055058240890503, 2542, 0.0007257323886943451]
2023-12-07 12:42:22,316	base	INFO	Train Epoch: 2 [8000/12500 (64%)]	Loss: 1.384473
2023-12-07 12:42:22,318	base	INFO	[0.17685425281524658, 1.2076184749603271, 2562, 0.0007314378320016906]
2023-12-07 12:42:38,457	base	INFO	Train Epoch: 2 [8160/12500 (65%)]	Loss: 1.304906
2023-12-07 12:42:38,467	base	INFO	[0.1672462821006775, 1.1376595497131348, 2582, 0.000737143275309036]
2023-12-07 12:42:55,385	base	INFO	Train Epoch: 2 [8320/12500 (67%)]	Loss: 1.280232
2023-12-07 12:42:55,387	base	INFO	[0.1665269136428833, 1.113705039024353, 2602, 0.0007428487186163815]
2023-12-07 12:43:12,210	base	INFO	Train Epoch: 2 [8480/12500 (68%)]	Loss: 1.286864
2023-12-07 12:43:12,211	base	INFO	[0.1657235026359558, 1.1211405992507935, 2622, 0.000748554161923727]
2023-12-07 12:43:28,415	base	INFO	Train Epoch: 2 [8640/12500 (69%)]	Loss: 1.264855
2023-12-07 12:43:28,417	base	INFO	[0.18089598417282104, 1.0839591026306152, 2642, 0.0007542596052310726]
2023-12-07 12:43:44,731	base	INFO	Train Epoch: 2 [8800/12500 (70%)]	Loss: 1.356194
2023-12-07 12:43:44,735	base	INFO	[0.17460846900939941, 1.181585431098938, 2662, 0.000759965048538418]
2023-12-07 12:44:00,779	base	INFO	Train Epoch: 2 [8960/12500 (72%)]	Loss: 1.332710
2023-12-07 12:44:00,782	base	INFO	[0.17244058847427368, 1.1602693796157837, 2682, 0.0007656704918457634]
2023-12-07 12:44:16,710	base	INFO	Train Epoch: 2 [9120/12500 (73%)]	Loss: 1.292309
2023-12-07 12:44:16,713	base	INFO	[0.1703176498413086, 1.1219909191131592, 2702, 0.000771375935153109]
2023-12-07 12:44:32,828	base	INFO	Train Epoch: 2 [9280/12500 (74%)]	Loss: 1.333214
2023-12-07 12:44:32,832	base	INFO	[0.1709844470024109, 1.1622295379638672, 2722, 0.0007770813784604545]
2023-12-07 12:44:50,332	base	INFO	Train Epoch: 2 [9440/12500 (76%)]	Loss: 1.328804
2023-12-07 12:44:50,341	base	INFO	[0.16138345003128052, 1.1674208641052246, 2742, 0.0007827868217677999]
2023-12-07 12:45:06,575	base	INFO	Train Epoch: 2 [9600/12500 (77%)]	Loss: 1.330088
2023-12-07 12:45:06,582	base	INFO	[0.15960615873336792, 1.1704821586608887, 2762, 0.0007884922650751454]
2023-12-07 12:45:23,083	base	INFO	Train Epoch: 2 [9760/12500 (78%)]	Loss: 1.304306
2023-12-07 12:45:23,092	base	INFO	[0.16530072689056396, 1.1390049457550049, 2782, 0.0007941977083824909]
2023-12-07 12:45:39,429	base	INFO	Train Epoch: 2 [9920/12500 (79%)]	Loss: 1.322114
2023-12-07 12:45:39,438	base	INFO	[0.1686718463897705, 1.1534417867660522, 2802, 0.0007999031516898363]
2023-12-07 12:45:56,714	base	INFO	Train Epoch: 2 [10080/12500 (81%)]	Loss: 1.245473
2023-12-07 12:45:56,717	base	INFO	[0.15951120853424072, 1.085961937904358, 2822, 0.0008056085949971819]
2023-12-07 12:46:13,272	base	INFO	Train Epoch: 2 [10240/12500 (82%)]	Loss: 1.283216
2023-12-07 12:46:13,274	base	INFO	[0.165363609790802, 1.1178520917892456, 2842, 0.0008113140383045273]
2023-12-07 12:46:29,509	base	INFO	Train Epoch: 2 [10400/12500 (83%)]	Loss: 1.324656
2023-12-07 12:46:29,512	base	INFO	[0.1720871925354004, 1.1525683403015137, 2862, 0.0008170194816118728]
2023-12-07 12:46:45,543	base	INFO	Train Epoch: 2 [10560/12500 (85%)]	Loss: 1.237867
2023-12-07 12:46:45,545	base	INFO	[0.16887354850769043, 1.0689936876296997, 2882, 0.0008227249249192183]
2023-12-07 12:47:02,605	base	INFO	Train Epoch: 2 [10720/12500 (86%)]	Loss: 1.242903
2023-12-07 12:47:02,609	base	INFO	[0.16118741035461426, 1.0817155838012695, 2902, 0.0008284303682265637]
2023-12-07 12:47:18,951	base	INFO	Train Epoch: 2 [10880/12500 (87%)]	Loss: 1.254801
2023-12-07 12:47:18,955	base	INFO	[0.16318738460540771, 1.091614007949829, 2922, 0.0008341358115339091]
2023-12-07 12:47:34,789	base	INFO	Train Epoch: 2 [11040/12500 (88%)]	Loss: 1.255967
2023-12-07 12:47:34,795	base	INFO	[0.1555628776550293, 1.100404143333435, 2942, 0.0008398412548412548]
2023-12-07 12:47:50,837	base	INFO	Train Epoch: 2 [11200/12500 (90%)]	Loss: 1.299785
2023-12-07 12:47:50,847	base	INFO	[0.15792077779769897, 1.1418641805648804, 2962, 0.0008455466981486002]
2023-12-07 12:48:06,978	base	INFO	Train Epoch: 2 [11360/12500 (91%)]	Loss: 1.338696
2023-12-07 12:48:06,988	base	INFO	[0.15938293933868408, 1.1793129444122314, 2982, 0.0008512521414559456]
2023-12-07 12:48:23,290	base	INFO	Train Epoch: 2 [11520/12500 (92%)]	Loss: 1.317588
2023-12-07 12:48:23,299	base	INFO	[0.1651478409767151, 1.152439832687378, 3002, 0.0008569575847632912]
2023-12-07 12:48:39,559	base	INFO	Train Epoch: 2 [11680/12500 (93%)]	Loss: 1.344715
2023-12-07 12:48:39,560	base	INFO	[0.17201805114746094, 1.172696828842163, 3022, 0.0008626630280706366]
2023-12-07 12:48:56,504	base	INFO	Train Epoch: 2 [11840/12500 (95%)]	Loss: 1.364300
2023-12-07 12:48:56,506	base	INFO	[0.16727906465530396, 1.1970210075378418, 3042, 0.000868368471377982]
2023-12-07 12:49:12,729	base	INFO	Train Epoch: 2 [12000/12500 (96%)]	Loss: 1.315083
2023-12-07 12:49:12,732	base	INFO	[0.15529263019561768, 1.1597899198532104, 3062, 0.0008740739146853276]
2023-12-07 12:49:29,161	base	INFO	Train Epoch: 2 [12160/12500 (97%)]	Loss: 1.297359
2023-12-07 12:49:29,164	base	INFO	[0.14637768268585205, 1.1509815454483032, 3082, 0.0008797793579926731]
2023-12-07 12:49:45,647	base	INFO	Train Epoch: 2 [12320/12500 (99%)]	Loss: 1.275556
2023-12-07 12:49:45,651	base	INFO	[0.14973300695419312, 1.125822901725769, 3102, 0.0008854848013000185]
2023-12-07 12:50:01,520	base	INFO	Train Epoch: 2 [12480/12500 (100%)]	Loss: 1.248039
2023-12-07 12:50:01,525	base	INFO	[0.1485118269920349, 1.0995266437530518, 3122, 0.000891190244607364]
2023-12-07 12:50:02,762	base	INFO	====> Epoch: 2
2023-12-07 12:50:03,357	base	INFO	Eval Epoch: 2 [0/100 (0%)]	Loss: 2.347188
2023-12-07 12:50:03,357	base	INFO	[0.14159685373306274, 2.2055909633636475]
2023-12-07 12:50:06,212	base	INFO	====> Epoch: 2
2023-12-07 12:50:06,212	base	INFO	Saving model and optimizer state at iteration 2 to ./logs/base/G_2.pdparams
2023-12-07 12:50:08,640	base	INFO	Train Epoch: 3 [0/12500 (0%)]	Loss: 1.317739
2023-12-07 12:50:08,640	base	INFO	[0.1637866497039795, 1.153952717781067, 3124, 0.0008917607889380986]
2023-12-07 12:50:24,526	base	INFO	Train Epoch: 3 [160/12500 (1%)]	Loss: 1.314644
2023-12-07 12:50:24,534	base	INFO	[0.15341299772262573, 1.1612306833267212, 3144, 0.0008974662322454441]
2023-12-07 12:50:40,812	base	INFO	Train Epoch: 3 [320/12500 (3%)]	Loss: 1.223615
2023-12-07 12:50:40,820	base	INFO	[0.14178001880645752, 1.0818349123001099, 3164, 0.0009031716755527895]
2023-12-07 12:50:58,004	base	INFO	Train Epoch: 3 [480/12500 (4%)]	Loss: 1.242421
2023-12-07 12:50:58,012	base	INFO	[0.16575264930725098, 1.0766681432724, 3184, 0.0009088771188601349]
2023-12-07 12:51:14,298	base	INFO	Train Epoch: 3 [640/12500 (5%)]	Loss: 1.388291
2023-12-07 12:51:14,299	base	INFO	[0.16509461402893066, 1.2231967449188232, 3204, 0.0009145825621674806]
2023-12-07 12:51:30,368	base	INFO	Train Epoch: 3 [800/12500 (6%)]	Loss: 1.250968
2023-12-07 12:51:30,370	base	INFO	[0.13751959800720215, 1.1134487390518188, 3224, 0.000920288005474826]
2023-12-07 12:51:46,397	base	INFO	Train Epoch: 3 [960/12500 (8%)]	Loss: 1.265071
2023-12-07 12:51:46,399	base	INFO	[0.14522165060043335, 1.119849443435669, 3244, 0.0009259934487821714]
2023-12-07 12:52:02,678	base	INFO	Train Epoch: 3 [1120/12500 (9%)]	Loss: 1.243651
2023-12-07 12:52:02,679	base	INFO	[0.15264683961868286, 1.0910037755966187, 3264, 0.000931698892089517]
2023-12-07 12:52:18,398	base	INFO	Train Epoch: 3 [1280/12500 (10%)]	Loss: 1.298882
2023-12-07 12:52:18,404	base	INFO	[0.14885538816452026, 1.1500269174575806, 3284, 0.0009374043353968624]
2023-12-07 12:52:34,403	base	INFO	Train Epoch: 3 [1440/12500 (12%)]	Loss: 1.308673
2023-12-07 12:52:34,413	base	INFO	[0.14672625064849854, 1.1619462966918945, 3304, 0.0009431097787042079]
2023-12-07 12:52:50,441	base	INFO	Train Epoch: 3 [1600/12500 (13%)]	Loss: 1.239513
2023-12-07 12:52:50,450	base	INFO	[0.14237594604492188, 1.0971366167068481, 3324, 0.0009488152220115534]
2023-12-07 12:53:07,483	base	INFO	Train Epoch: 3 [1760/12500 (14%)]	Loss: 1.198556
2023-12-07 12:53:07,489	base	INFO	[0.13567817211151123, 1.0628777742385864, 3344, 0.0009545206653188989]
2023-12-07 12:53:23,777	base	INFO	Train Epoch: 3 [1920/12500 (15%)]	Loss: 1.279150
2023-12-07 12:53:23,785	base	INFO	[0.1467481255531311, 1.1324024200439453, 3364, 0.0009602261086262443]
2023-12-07 12:53:40,015	base	INFO	Train Epoch: 3 [2080/12500 (17%)]	Loss: 1.287991
2023-12-07 12:53:40,017	base	INFO	[0.1364459991455078, 1.1515451669692993, 3384, 0.0009659315519335898]
2023-12-07 12:53:56,401	base	INFO	Train Epoch: 3 [2240/12500 (18%)]	Loss: 1.187413
2023-12-07 12:53:56,402	base	INFO	[0.14283353090286255, 1.044579267501831, 3404, 0.0009716369952409354]
2023-12-07 12:54:12,703	base	INFO	Train Epoch: 3 [2400/12500 (19%)]	Loss: 1.272358
2023-12-07 12:54:12,706	base	INFO	[0.13944685459136963, 1.1329113245010376, 3424, 0.0009773424385482808]
2023-12-07 12:54:28,629	base	INFO	Train Epoch: 3 [2560/12500 (20%)]	Loss: 1.319032
2023-12-07 12:54:28,631	base	INFO	[0.1550951600074768, 1.163936972618103, 3444, 0.0009830478818556262]
2023-12-07 12:54:45,221	base	INFO	Train Epoch: 3 [2720/12500 (22%)]	Loss: 1.323650
2023-12-07 12:54:45,228	base	INFO	[0.14118129014968872, 1.182469129562378, 3464, 0.0009887533251629718]
2023-12-07 12:55:01,934	base	INFO	Train Epoch: 3 [2880/12500 (23%)]	Loss: 1.301279
2023-12-07 12:55:01,937	base	INFO	[0.14957624673843384, 1.1517027616500854, 3484, 0.0009944587684703173]
2023-12-07 12:55:18,074	base	INFO	Train Epoch: 3 [3040/12500 (24%)]	Loss: 1.280853
2023-12-07 12:55:18,079	base	INFO	[0.14152759313583374, 1.1393252611160278, 3504, 0.0010001642117776627]
2023-12-07 12:55:34,176	base	INFO	Train Epoch: 3 [3200/12500 (26%)]	Loss: 1.288691
2023-12-07 12:55:34,185	base	INFO	[0.15798157453536987, 1.130709171295166, 3524, 0.001005869655085008]
2023-12-07 12:55:50,129	base	INFO	Train Epoch: 3 [3360/12500 (27%)]	Loss: 1.279195
2023-12-07 12:55:50,138	base	INFO	[0.14531207084655762, 1.1338831186294556, 3544, 0.0010115750983923535]
2023-12-07 12:56:06,226	base	INFO	Train Epoch: 3 [3520/12500 (28%)]	Loss: 1.256012
2023-12-07 12:56:06,231	base	INFO	[0.14440101385116577, 1.111610770225525, 3564, 0.0010172805416996992]
2023-12-07 12:56:21,949	base	INFO	Train Epoch: 3 [3680/12500 (29%)]	Loss: 1.250864
2023-12-07 12:56:21,957	base	INFO	[0.14080113172531128, 1.110063076019287, 3584, 0.0010229859850070446]
2023-12-07 12:56:39,085	base	INFO	Train Epoch: 3 [3840/12500 (31%)]	Loss: 1.271185
2023-12-07 12:56:39,085	base	INFO	[0.14812594652175903, 1.1230592727661133, 3604, 0.0010286914283143902]
2023-12-07 12:56:55,066	base	INFO	Train Epoch: 3 [4000/12500 (32%)]	Loss: 1.249297
2023-12-07 12:56:55,069	base	INFO	[0.16117358207702637, 1.0881239175796509, 3624, 0.0010343968716217357]
2023-12-07 12:57:12,041	base	INFO	Train Epoch: 3 [4160/12500 (33%)]	Loss: 1.190106
2023-12-07 12:57:12,044	base	INFO	[0.1364811658859253, 1.0536243915557861, 3644, 0.001040102314929081]
2023-12-07 12:57:28,002	base	INFO	Train Epoch: 3 [4320/12500 (35%)]	Loss: 1.240175
2023-12-07 12:57:28,004	base	INFO	[0.14654022455215454, 1.093635082244873, 3664, 0.0010458077582364267]
2023-12-07 12:57:44,362	base	INFO	Train Epoch: 3 [4480/12500 (36%)]	Loss: 1.307058
2023-12-07 12:57:44,364	base	INFO	[0.13430005311965942, 1.1727581024169922, 3684, 0.0010515132015437721]
2023-12-07 12:58:00,763	base	INFO	Train Epoch: 3 [4640/12500 (37%)]	Loss: 1.314386
2023-12-07 12:58:00,765	base	INFO	[0.1420227289199829, 1.1723636388778687, 3704, 0.0010572186448511176]
2023-12-07 12:58:16,999	base	INFO	Train Epoch: 3 [4800/12500 (38%)]	Loss: 1.267042
2023-12-07 12:58:17,001	base	INFO	[0.13892865180969238, 1.1281137466430664, 3724, 0.001062924088158463]
2023-12-07 12:58:33,022	base	INFO	Train Epoch: 3 [4960/12500 (40%)]	Loss: 1.250535
2023-12-07 12:58:33,028	base	INFO	[0.1440737247467041, 1.1064610481262207, 3744, 0.0010686295314658084]
2023-12-07 12:58:49,527	base	INFO	Train Epoch: 3 [5120/12500 (41%)]	Loss: 1.255399
2023-12-07 12:58:49,535	base	INFO	[0.1348976492881775, 1.120500922203064, 3764, 0.0010743349747731538]
2023-12-07 12:59:06,715	base	INFO	Train Epoch: 3 [5280/12500 (42%)]	Loss: 1.285094
2023-12-07 12:59:06,724	base	INFO	[0.12658369541168213, 1.1585108041763306, 3784, 0.0010800404180804995]
2023-12-07 12:59:23,513	base	INFO	Train Epoch: 3 [5440/12500 (44%)]	Loss: 1.343618
2023-12-07 12:59:23,515	base	INFO	[0.13467860221862793, 1.2089394330978394, 3804, 0.0010857458613878449]
2023-12-07 12:59:39,589	base	INFO	Train Epoch: 3 [5600/12500 (45%)]	Loss: 1.243640
2023-12-07 12:59:39,590	base	INFO	[0.11793935298919678, 1.1257010698318481, 3824, 0.0010914513046951903]
2023-12-07 12:59:55,620	base	INFO	Train Epoch: 3 [5760/12500 (46%)]	Loss: 1.242063
2023-12-07 12:59:55,622	base	INFO	[0.12897568941116333, 1.1130869388580322, 3844, 0.001097156748002536]
2023-12-07 13:00:12,106	base	INFO	Train Epoch: 3 [5920/12500 (47%)]	Loss: 1.300678
2023-12-07 13:00:12,108	base	INFO	[0.13001000881195068, 1.1706676483154297, 3864, 0.0011028621913098814]
2023-12-07 13:00:27,913	base	INFO	Train Epoch: 3 [6080/12500 (49%)]	Loss: 1.215619
2023-12-07 13:00:27,915	base	INFO	[0.14309817552566528, 1.0725206136703491, 3884, 0.0011085676346172268]
2023-12-07 13:00:44,041	base	INFO	Train Epoch: 3 [6240/12500 (50%)]	Loss: 1.249339
2023-12-07 13:00:44,043	base	INFO	[0.13492155075073242, 1.1144174337387085, 3904, 0.0011142730779245724]
2023-12-07 13:01:00,309	base	INFO	Train Epoch: 3 [6400/12500 (51%)]	Loss: 1.253333
2023-12-07 13:01:00,316	base	INFO	[0.13963210582733154, 1.1137007474899292, 3924, 0.0011199785212319179]
2023-12-07 13:01:17,165	base	INFO	Train Epoch: 3 [6560/12500 (52%)]	Loss: 1.269386
2023-12-07 13:01:17,173	base	INFO	[0.14670729637145996, 1.1226791143417358, 3944, 0.0011256839645392633]
2023-12-07 13:01:33,748	base	INFO	Train Epoch: 3 [6720/12500 (54%)]	Loss: 1.281676
2023-12-07 13:01:33,756	base	INFO	[0.14382827281951904, 1.137848138809204, 3964, 0.0011313894078466087]
2023-12-07 13:01:49,782	base	INFO	Train Epoch: 3 [6880/12500 (55%)]	Loss: 1.294785
2023-12-07 13:01:49,792	base	INFO	[0.12985610961914062, 1.164928674697876, 3984, 0.0011370948511539541]
2023-12-07 13:02:06,147	base	INFO	Train Epoch: 3 [7040/12500 (56%)]	Loss: 1.237596
2023-12-07 13:02:06,148	base	INFO	[0.13440704345703125, 1.1031891107559204, 4004, 0.0011402338065646378]
2023-12-07 13:02:22,116	base	INFO	Train Epoch: 3 [7200/12500 (58%)]	Loss: 1.238653
2023-12-07 13:02:22,117	base	INFO	[0.1126631498336792, 1.1259899139404297, 4024, 0.001137398105067946]
2023-12-07 13:02:38,498	base	INFO	Train Epoch: 3 [7360/12500 (59%)]	Loss: 1.299730
2023-12-07 13:02:38,501	base	INFO	[0.12403595447540283, 1.1756941080093384, 4044, 0.0011345834556036169]
2023-12-07 13:02:54,220	base	INFO	Train Epoch: 3 [7520/12500 (60%)]	Loss: 1.198415
2023-12-07 13:02:54,222	base	INFO	[0.11241698265075684, 1.085998296737671, 4064, 0.001131789598973088]
2023-12-07 13:03:10,813	base	INFO	Train Epoch: 3 [7680/12500 (61%)]	Loss: 1.192578
2023-12-07 13:03:10,815	base	INFO	[0.12066251039505005, 1.0719153881072998, 4084, 0.00112901628042376]
2023-12-07 13:03:26,862	base	INFO	Train Epoch: 3 [7840/12500 (63%)]	Loss: 1.258322
2023-12-07 13:03:26,867	base	INFO	[0.13115066289901733, 1.1271718740463257, 4104, 0.001126263249551429]
2023-12-07 13:03:42,819	base	INFO	Train Epoch: 3 [8000/12500 (64%)]	Loss: 1.320184
2023-12-07 13:03:42,827	base	INFO	[0.1300828456878662, 1.1901012659072876, 4124, 0.0011235302602053167]
2023-12-07 13:03:58,510	base	INFO	Train Epoch: 3 [8160/12500 (65%)]	Loss: 1.270160
2023-12-07 13:03:58,519	base	INFO	[0.12070047855377197, 1.1494592428207397, 4144, 0.0011208170703956286]
2023-12-07 13:04:14,295	base	INFO	Train Epoch: 3 [8320/12500 (67%)]	Loss: 1.252455
2023-12-07 13:04:14,297	base	INFO	[0.11951959133148193, 1.1329350471496582, 4164, 0.0011181234422035524]
2023-12-07 13:04:30,181	base	INFO	Train Epoch: 3 [8480/12500 (68%)]	Loss: 1.210317
2023-12-07 13:04:30,190	base	INFO	[0.11866706609725952, 1.0916495323181152, 4184, 0.0011154491416936268]
2023-12-07 13:04:46,956	base	INFO	Train Epoch: 3 [8640/12500 (69%)]	Loss: 1.226846
2023-12-07 13:04:46,958	base	INFO	[0.13443320989608765, 1.0924129486083984, 4204, 0.0011127939388284032]
2023-12-07 13:05:03,579	base	INFO	Train Epoch: 3 [8800/12500 (70%)]	Loss: 1.257973
2023-12-07 13:05:03,582	base	INFO	[0.12886136770248413, 1.1291117668151855, 4224, 0.0011101576073853324]
2023-12-07 13:05:20,603	base	INFO	Train Epoch: 3 [8960/12500 (72%)]	Loss: 1.220025
2023-12-07 13:05:20,606	base	INFO	[0.12858819961547852, 1.0914368629455566, 4244, 0.0011075399248758068]
2023-12-07 13:05:36,896	base	INFO	Train Epoch: 3 [9120/12500 (73%)]	Loss: 1.236598
2023-12-07 13:05:36,899	base	INFO	[0.12643247842788696, 1.1101658344268799, 4264, 0.0011049406724662916]
2023-12-07 13:05:53,060	base	INFO	Train Epoch: 3 [9280/12500 (74%)]	Loss: 1.224391
2023-12-07 13:05:53,063	base	INFO	[0.12737208604812622, 1.0970183610916138, 4284, 0.0011023596349014843]
2023-12-07 13:06:09,523	base	INFO	Train Epoch: 3 [9440/12500 (76%)]	Loss: 1.229106
2023-12-07 13:06:09,526	base	INFO	[0.11430543661117554, 1.1148008108139038, 4304, 0.0010997966004294374]
2023-12-07 13:06:25,641	base	INFO	Train Epoch: 3 [9600/12500 (77%)]	Loss: 1.292560
2023-12-07 13:06:25,645	base	INFO	[0.1166461706161499, 1.1759138107299805, 4324, 0.0010972513607285903]
2023-12-07 13:06:41,760	base	INFO	Train Epoch: 3 [9760/12500 (78%)]	Loss: 1.278201
2023-12-07 13:06:41,763	base	INFO	[0.12128490209579468, 1.1569163799285889, 4344, 0.0010947237108366453]
2023-12-07 13:06:57,806	base	INFO	Train Epoch: 3 [9920/12500 (79%)]	Loss: 1.232892
2023-12-07 13:06:57,815	base	INFO	[0.12479627132415771, 1.1080952882766724, 4364, 0.0010922134490812438]
2023-12-07 13:07:14,849	base	INFO	Train Epoch: 3 [10080/12500 (81%)]	Loss: 1.231872
2023-12-07 13:07:14,859	base	INFO	[0.11714315414428711, 1.1147288084030151, 4384, 0.0010897203770123779]
2023-12-07 13:07:31,922	base	INFO	Train Epoch: 3 [10240/12500 (82%)]	Loss: 1.239742
2023-12-07 13:07:31,924	base	INFO	[0.12261873483657837, 1.1171234846115112, 4404, 0.0010872442993364938]
2023-12-07 13:07:48,018	base	INFO	Train Epoch: 3 [10400/12500 (83%)]	Loss: 1.264921
2023-12-07 13:07:48,020	base	INFO	[0.12758082151412964, 1.1373398303985596, 4424, 0.0010847850238522342]
2023-12-07 13:08:04,111	base	INFO	Train Epoch: 3 [10560/12500 (85%)]	Loss: 1.227696
2023-12-07 13:08:04,113	base	INFO	[0.12549859285354614, 1.1021977663040161, 4444, 0.001082342361387773]
2023-12-07 13:08:19,956	base	INFO	Train Epoch: 3 [10720/12500 (86%)]	Loss: 1.137731
2023-12-07 13:08:19,959	base	INFO	[0.11913233995437622, 1.0185986757278442, 4464, 0.0010799161257396945]
2023-12-07 13:08:36,330	base	INFO	Train Epoch: 3 [10880/12500 (87%)]	Loss: 1.216571
2023-12-07 13:08:36,335	base	INFO	[0.11984872817993164, 1.0967226028442383, 4484, 0.0010775061336133723]
2023-12-07 13:08:52,927	base	INFO	Train Epoch: 3 [11040/12500 (88%)]	Loss: 1.159904
2023-12-07 13:08:52,930	base	INFO	[0.11096972227096558, 1.0489343404769897, 4504, 0.001075112204564808]
2023-12-07 13:09:09,180	base	INFO	Train Epoch: 3 [11200/12500 (90%)]	Loss: 1.196732
2023-12-07 13:09:09,190	base	INFO	[0.11255699396133423, 1.0841745138168335, 4524, 0.0010727341609438812]
2023-12-07 13:09:26,031	base	INFO	Train Epoch: 3 [11360/12500 (91%)]	Loss: 1.191143
2023-12-07 13:09:26,035	base	INFO	[0.11903703212738037, 1.0721063613891602, 4544, 0.0010703718278389774]
2023-12-07 13:09:42,308	base	INFO	Train Epoch: 3 [11520/12500 (92%)]	Loss: 1.216710
2023-12-07 13:09:42,318	base	INFO	[0.12245768308639526, 1.094252586364746, 4564, 0.00106802503302295]
2023-12-07 13:09:58,435	base	INFO	Train Epoch: 3 [11680/12500 (93%)]	Loss: 1.303067
2023-12-07 13:09:58,443	base	INFO	[0.12884438037872314, 1.1742230653762817, 4584, 0.0010656936069003797]
2023-12-07 13:10:14,661	base	INFO	Train Epoch: 3 [11840/12500 (95%)]	Loss: 1.281807
2023-12-07 13:10:14,662	base	INFO	[0.12541240453720093, 1.1563948392868042, 4604, 0.0010633773824560958]
2023-12-07 13:10:30,782	base	INFO	Train Epoch: 3 [12000/12500 (96%)]	Loss: 1.203871
2023-12-07 13:10:30,783	base	INFO	[0.11253362894058228, 1.0913370847702026, 4624, 0.0010610761952049212]
2023-12-07 13:10:46,709	base	INFO	Train Epoch: 3 [12160/12500 (97%)]	Loss: 1.242317
2023-12-07 13:10:46,713	base	INFO	[0.10531872510910034, 1.1369984149932861, 4644, 0.0010587898831426103]
2023-12-07 13:11:03,000	base	INFO	Train Epoch: 3 [12320/12500 (99%)]	Loss: 1.144104
2023-12-07 13:11:03,003	base	INFO	[0.10708564519882202, 1.0370187759399414, 4664, 0.001056518286697945]
2023-12-07 13:11:19,745	base	INFO	Train Epoch: 3 [12480/12500 (100%)]	Loss: 1.215587
2023-12-07 13:11:19,748	base	INFO	[0.1030002236366272, 1.112586498260498, 4684, 0.001054261248685953]
2023-12-07 13:11:21,014	base	INFO	====> Epoch: 3
2023-12-07 13:11:21,610	base	INFO	Eval Epoch: 3 [0/100 (0%)]	Loss: 1.710602
2023-12-07 13:11:21,610	base	INFO	[0.10279816389083862, 1.6078037023544312]
2023-12-07 13:11:24,420	base	INFO	====> Epoch: 3
2023-12-07 13:11:24,420	base	INFO	Saving model and optimizer state at iteration 3 to ./logs/base/G_3.pdparams
2023-12-07 13:11:26,975	base	INFO	Train Epoch: 4 [0/12500 (0%)]	Loss: 1.209302
2023-12-07 13:11:26,976	base	INFO	[0.12075239419937134, 1.0885493755340576, 4686, 0.0010540363396170074]
2023-12-07 13:11:43,106	base	INFO	Train Epoch: 4 [160/12500 (1%)]	Loss: 1.285706
2023-12-07 13:11:43,114	base	INFO	[0.11101388931274414, 1.1746923923492432, 4706, 0.001051795137124439]
2023-12-07 13:11:58,997	base	INFO	Train Epoch: 4 [320/12500 (3%)]	Loss: 1.223679
2023-12-07 13:11:58,999	base	INFO	[0.09934341907501221, 1.1243360042572021, 4726, 0.0010495681705414133]
2023-12-07 13:12:15,493	base	INFO	Train Epoch: 4 [480/12500 (4%)]	Loss: 1.187550
2023-12-07 13:12:15,502	base	INFO	[0.12536859512329102, 1.062180995941162, 4746, 0.001047355289794699]
2023-12-07 13:12:31,684	base	INFO	Train Epoch: 4 [640/12500 (5%)]	Loss: 1.267355
2023-12-07 13:12:31,695	base	INFO	[0.12417709827423096, 1.1431775093078613, 4766, 0.0010451563470166424]
2023-12-07 13:12:48,265	base	INFO	Train Epoch: 4 [800/12500 (6%)]	Loss: 1.175452
2023-12-07 13:12:48,266	base	INFO	[0.09693717956542969, 1.0785150527954102, 4786, 0.0010429711965036642]
2023-12-07 13:13:04,139	base	INFO	Train Epoch: 4 [960/12500 (8%)]	Loss: 1.117805
2023-12-07 13:13:04,141	base	INFO	[0.1023942232131958, 1.0154109001159668, 4806, 0.0010407996946757091]
2023-12-07 13:13:21,300	base	INFO	Train Epoch: 4 [1120/12500 (9%)]	Loss: 1.186210
2023-12-07 13:13:21,303	base	INFO	[0.1118658185005188, 1.0743439197540283, 4826, 0.0010386417000366186]
2023-12-07 13:13:37,465	base	INFO	Train Epoch: 4 [1280/12500 (10%)]	Loss: 1.282590
2023-12-07 13:13:37,467	base	INFO	[0.10795778036117554, 1.1746325492858887, 4846, 0.0010364970731354052]
2023-12-07 13:13:53,753	base	INFO	Train Epoch: 4 [1440/12500 (12%)]	Loss: 1.160784
2023-12-07 13:13:53,756	base	INFO	[0.10640090703964233, 1.0543831586837769, 4866, 0.0010343656765284027]
2023-12-07 13:14:10,063	base	INFO	Train Epoch: 4 [1600/12500 (13%)]	Loss: 1.177111
2023-12-07 13:14:10,069	base	INFO	[0.09751653671264648, 1.0795941352844238, 4886, 0.001032247374742267]
2023-12-07 13:14:26,618	base	INFO	Train Epoch: 4 [1760/12500 (14%)]	Loss: 1.130666
2023-12-07 13:14:26,627	base	INFO	[0.09220880270004272, 1.0384576320648193, 4906, 0.0010301420342378098]
2023-12-07 13:14:43,101	base	INFO	Train Epoch: 4 [1920/12500 (15%)]	Loss: 1.181992
2023-12-07 13:14:43,110	base	INFO	[0.10737830400466919, 1.0746135711669922, 4926, 0.001028049523374639]
2023-12-07 13:14:59,281	base	INFO	Train Epoch: 4 [2080/12500 (17%)]	Loss: 1.240053
2023-12-07 13:14:59,283	base	INFO	[0.09435790777206421, 1.1456948518753052, 4946, 0.0010259697123765853]
2023-12-07 13:15:15,215	base	INFO	Train Epoch: 4 [2240/12500 (18%)]	Loss: 1.161720
2023-12-07 13:15:15,223	base	INFO	[0.10050803422927856, 1.0612115859985352, 4966, 0.0010239024732978967]
2023-12-07 13:15:32,702	base	INFO	Train Epoch: 4 [2400/12500 (19%)]	Loss: 1.193294
2023-12-07 13:15:32,704	base	INFO	[0.09969627857208252, 1.0935978889465332, 4986, 0.001021847679990178]
2023-12-07 13:15:49,014	base	INFO	Train Epoch: 4 [2560/12500 (20%)]	Loss: 1.236427
2023-12-07 13:15:49,016	base	INFO	[0.11452829837799072, 1.1218990087509155, 5006, 0.0010198052080700587]
2023-12-07 13:16:05,058	base	INFO	Train Epoch: 4 [2720/12500 (22%)]	Loss: 1.309471
2023-12-07 13:16:05,061	base	INFO	[0.09919756650924683, 1.2102733850479126, 5026, 0.0010177749348875655]
2023-12-07 13:16:21,008	base	INFO	Train Epoch: 4 [2880/12500 (23%)]	Loss: 1.119540
2023-12-07 13:16:21,012	base	INFO	[0.10734134912490845, 1.0121984481811523, 5046, 0.0010157567394951902]
2023-12-07 13:16:36,692	base	INFO	Train Epoch: 4 [3040/12500 (24%)]	Loss: 1.165983
2023-12-07 13:16:36,694	base	INFO	[0.09853959083557129, 1.0674430131912231, 5066, 0.0010137505026176236]
2023-12-07 13:16:52,982	base	INFO	Train Epoch: 4 [3200/12500 (26%)]	Loss: 1.208707
2023-12-07 13:16:52,986	base	INFO	[0.11688274145126343, 1.0918240547180176, 5086, 0.00101175610662215]
2023-12-07 13:17:09,057	base	INFO	Train Epoch: 4 [3360/12500 (27%)]	Loss: 1.186017
2023-12-07 13:17:09,060	base	INFO	[0.10616457462310791, 1.0798524618148804, 5106, 0.0010097734354896752]
2023-12-07 13:17:25,963	base	INFO	Train Epoch: 4 [3520/12500 (28%)]	Loss: 1.171185
2023-12-07 13:17:25,972	base	INFO	[0.10360199213027954, 1.0675832033157349, 5126, 0.0010078023747863787]
2023-12-07 13:17:41,616	base	INFO	Train Epoch: 4 [3680/12500 (29%)]	Loss: 1.179813
2023-12-07 13:17:41,625	base	INFO	[0.09966772794723511, 1.0801451206207275, 5146, 0.001005842811635974]
2023-12-07 13:17:57,836	base	INFO	Train Epoch: 4 [3840/12500 (31%)]	Loss: 1.192519
2023-12-07 13:17:57,845	base	INFO	[0.10878884792327881, 1.0837305784225464, 5166, 0.0010038946346925554]
2023-12-07 13:18:14,620	base	INFO	Train Epoch: 4 [4000/12500 (32%)]	Loss: 1.191364
2023-12-07 13:18:14,621	base	INFO	[0.12285095453262329, 1.0685127973556519, 5186, 0.0010019577341140254]
2023-12-07 13:18:30,534	base	INFO	Train Epoch: 4 [4160/12500 (33%)]	Loss: 1.102489
2023-12-07 13:18:30,536	base	INFO	[0.0964084267616272, 1.0060807466506958, 5206, 0.001000032001536082]
2023-12-07 13:18:46,676	base	INFO	Train Epoch: 4 [4320/12500 (35%)]	Loss: 1.186195
2023-12-07 13:18:46,679	base	INFO	[0.10640531778335571, 1.0797898769378662, 5226, 0.0009981173300467527]
2023-12-07 13:19:02,582	base	INFO	Train Epoch: 4 [4480/12500 (36%)]	Loss: 1.233173
2023-12-07 13:19:02,586	base	INFO	[0.09247249364852905, 1.1407009363174438, 5246, 0.000996213614161466]
2023-12-07 13:19:19,016	base	INFO	Train Epoch: 4 [4640/12500 (37%)]	Loss: 1.177951
2023-12-07 13:19:19,021	base	INFO	[0.10187077522277832, 1.0760798454284668, 5266, 0.0009943207497986409]
2023-12-07 13:19:36,008	base	INFO	Train Epoch: 4 [4800/12500 (38%)]	Loss: 1.208272
2023-12-07 13:19:36,018	base	INFO	[0.09847146272659302, 1.1098002195358276, 5286, 0.000992438634255786]
2023-12-07 13:19:52,170	base	INFO	Train Epoch: 4 [4960/12500 (40%)]	Loss: 1.143865
2023-12-07 13:19:52,180	base	INFO	[0.10599011182785034, 1.0378752946853638, 5306, 0.0009905671661860937]
2023-12-07 13:20:08,484	base	INFO	Train Epoch: 4 [5120/12500 (41%)]	Loss: 1.172906
2023-12-07 13:20:08,487	base	INFO	[0.09312814474105835, 1.0797778367996216, 5326, 0.0009887062455755198]
2023-12-07 13:20:24,779	base	INFO	Train Epoch: 4 [5280/12500 (42%)]	Loss: 1.140045
2023-12-07 13:20:24,790	base	INFO	[0.08681577444076538, 1.0532294511795044, 5346, 0.0009868557737203324]
2023-12-07 13:20:40,812	base	INFO	Train Epoch: 4 [5440/12500 (44%)]	Loss: 1.237961
2023-12-07 13:20:40,822	base	INFO	[0.09313130378723145, 1.1448297500610352, 5366, 0.0009850156532051233]
2023-12-07 13:20:57,592	base	INFO	Train Epoch: 4 [5600/12500 (45%)]	Loss: 1.169807
2023-12-07 13:20:57,593	base	INFO	[0.07993090152740479, 1.0898756980895996, 5386, 0.0009831857878812682]
2023-12-07 13:21:13,894	base	INFO	Train Epoch: 4 [5760/12500 (46%)]	Loss: 1.040231
2023-12-07 13:21:13,897	base	INFO	[0.08857345581054688, 0.9516574740409851, 5406, 0.0009813660828458246]
2023-12-07 13:21:30,888	base	INFO	Train Epoch: 4 [5920/12500 (47%)]	Loss: 1.195088
2023-12-07 13:21:30,891	base	INFO	[0.09127438068389893, 1.1038132905960083, 5426, 0.0009795564444208592]
2023-12-07 13:21:46,846	base	INFO	Train Epoch: 4 [6080/12500 (49%)]	Loss: 1.217999
2023-12-07 13:21:46,849	base	INFO	[0.1017487645149231, 1.1162506341934204, 5446, 0.0009777567801331918]
2023-12-07 13:22:03,149	base	INFO	Train Epoch: 4 [6240/12500 (50%)]	Loss: 1.117369
2023-12-07 13:22:03,152	base	INFO	[0.09559392929077148, 1.021775245666504, 5466, 0.0009759669986945479]
2023-12-07 13:22:19,110	base	INFO	Train Epoch: 4 [6400/12500 (51%)]	Loss: 1.094627
2023-12-07 13:22:19,112	base	INFO	[0.10027426481246948, 0.9943528175354004, 5486, 0.0009741870099821087]
2023-12-07 13:22:35,498	base	INFO	Train Epoch: 4 [6560/12500 (52%)]	Loss: 1.254578
2023-12-07 13:22:35,509	base	INFO	[0.10764509439468384, 1.1469333171844482, 5506, 0.0009724167250194512]
2023-12-07 13:22:51,800	base	INFO	Train Epoch: 4 [6720/12500 (54%)]	Loss: 1.152948
2023-12-07 13:22:51,803	base	INFO	[0.10576552152633667, 1.047182559967041, 5526, 0.0009706560559578658]
2023-12-07 13:23:08,070	base	INFO	Train Epoch: 4 [6880/12500 (55%)]	Loss: 1.199511
2023-12-07 13:23:08,080	base	INFO	[0.08888161182403564, 1.1106290817260742, 5546, 0.0009689049160580472]
2023-12-07 13:23:24,210	base	INFO	Train Epoch: 4 [7040/12500 (56%)]	Loss: 1.157278
2023-12-07 13:23:24,219	base	INFO	[0.0918508768081665, 1.065427303314209, 5566, 0.000967163219672145]
2023-12-07 13:23:41,762	base	INFO	Train Epoch: 4 [7200/12500 (58%)]	Loss: 1.100510
2023-12-07 13:23:41,765	base	INFO	[0.07734614610671997, 1.0231640338897705, 5586, 0.0009654308822261699]
2023-12-07 13:23:58,215	base	INFO	Train Epoch: 4 [7360/12500 (59%)]	Loss: 1.189906
2023-12-07 13:23:58,218	base	INFO	[0.09297096729278564, 1.096935510635376, 5606, 0.0009637078202027437]
2023-12-07 13:24:14,620	base	INFO	Train Epoch: 4 [7520/12500 (60%)]	Loss: 1.200674
2023-12-07 13:24:14,622	base	INFO	[0.08097386360168457, 1.1196998357772827, 5626, 0.0009619939511241877]
2023-12-07 13:24:30,276	base	INFO	Train Epoch: 4 [7680/12500 (61%)]	Loss: 1.073884
2023-12-07 13:24:30,278	base	INFO	[0.08887743949890137, 0.985007107257843, 5646, 0.0009602891935359408]
2023-12-07 13:24:46,419	base	INFO	Train Epoch: 4 [7840/12500 (63%)]	Loss: 1.155296
2023-12-07 13:24:46,422	base	INFO	[0.09907388687133789, 1.0562217235565186, 5666, 0.0009585934669902986]
2023-12-07 13:25:02,290	base	INFO	Train Epoch: 4 [8000/12500 (64%)]	Loss: 1.168437
2023-12-07 13:25:02,292	base	INFO	[0.09763246774673462, 1.0708045959472656, 5686, 0.0009569066920304694]
2023-12-07 13:25:18,600	base	INFO	Train Epoch: 4 [8160/12500 (65%)]	Loss: 1.092285
2023-12-07 13:25:18,606	base	INFO	[0.0860975980758667, 1.0061873197555542, 5706, 0.0009552287901749352]
2023-12-07 13:25:34,939	base	INFO	Train Epoch: 4 [8320/12500 (67%)]	Loss: 1.133262
2023-12-07 13:25:34,947	base	INFO	[0.08407247066497803, 1.049189567565918, 5726, 0.0009535596839021147]
2023-12-07 13:25:51,139	base	INFO	Train Epoch: 4 [8480/12500 (68%)]	Loss: 1.147786
2023-12-07 13:25:51,149	base	INFO	[0.08327746391296387, 1.0645089149475098, 5746, 0.0009518992966353204]
2023-12-07 13:26:07,048	base	INFO	Train Epoch: 4 [8640/12500 (69%)]	Loss: 1.058635
2023-12-07 13:26:07,058	base	INFO	[0.10133415460586548, 0.9573003649711609, 5766, 0.0009502475527280021]
2023-12-07 13:26:23,532	base	INFO	Train Epoch: 4 [8800/12500 (70%)]	Loss: 1.154859
2023-12-07 13:26:23,535	base	INFO	[0.0928531289100647, 1.0620059967041016, 5786, 0.0009486043774492704]
2023-12-07 13:26:39,664	base	INFO	Train Epoch: 4 [8960/12500 (72%)]	Loss: 1.154328
2023-12-07 13:26:39,665	base	INFO	[0.09462863206863403, 1.059699535369873, 5806, 0.0009469696969696969]
2023-12-07 13:26:55,670	base	INFO	Train Epoch: 4 [9120/12500 (73%)]	Loss: 1.156283
2023-12-07 13:26:55,672	base	INFO	[0.09280896186828613, 1.0634739398956299, 5826, 0.0009453434383473802]
2023-12-07 13:27:11,695	base	INFO	Train Epoch: 4 [9280/12500 (74%)]	Loss: 1.171558
2023-12-07 13:27:11,699	base	INFO	[0.09483510255813599, 1.0767232179641724, 5846, 0.0009437255295142754]
2023-12-07 13:27:27,615	base	INFO	Train Epoch: 4 [9440/12500 (76%)]	Loss: 1.154218
2023-12-07 13:27:27,618	base	INFO	[0.07925009727478027, 1.0749675035476685, 5866, 0.0009421158992627803]
2023-12-07 13:27:44,879	base	INFO	Train Epoch: 4 [9600/12500 (77%)]	Loss: 1.232503
2023-12-07 13:27:44,881	base	INFO	[0.08363431692123413, 1.1488690376281738, 5886, 0.0009405144772325719]
2023-12-07 13:28:00,614	base	INFO	Train Epoch: 4 [9760/12500 (78%)]	Loss: 1.172761
2023-12-07 13:28:00,620	base	INFO	[0.08806413412094116, 1.0846967697143555, 5906, 0.0009389211938976878]
2023-12-07 13:28:16,556	base	INFO	Train Epoch: 4 [9920/12500 (79%)]	Loss: 1.083031
2023-12-07 13:28:16,565	base	INFO	[0.09095406532287598, 0.9920772314071655, 5926, 0.000937335980553849]
2023-12-07 13:28:32,300	base	INFO	Train Epoch: 4 [10080/12500 (81%)]	Loss: 1.126737
2023-12-07 13:28:32,308	base	INFO	[0.08310937881469727, 1.0436276197433472, 5946, 0.0009357587693060157]
2023-12-07 13:28:48,637	base	INFO	Train Epoch: 4 [10240/12500 (82%)]	Loss: 1.101147
2023-12-07 13:28:48,646	base	INFO	[0.0880582332611084, 1.0130888223648071, 5966, 0.0009341894930561735]
2023-12-07 13:29:05,327	base	INFO	Train Epoch: 4 [10400/12500 (83%)]	Loss: 1.158350
2023-12-07 13:29:05,329	base	INFO	[0.09620821475982666, 1.0621412992477417, 5986, 0.0009326280854913443]
2023-12-07 13:29:21,575	base	INFO	Train Epoch: 4 [10560/12500 (85%)]	Loss: 1.192874
2023-12-07 13:29:21,578	base	INFO	[0.09288656711578369, 1.0999876260757446, 6006, 0.0009310744810718159]
2023-12-07 13:29:38,576	base	INFO	Train Epoch: 4 [10720/12500 (86%)]	Loss: 1.080750
2023-12-07 13:29:38,579	base	INFO	[0.08164626359939575, 0.9991041421890259, 6026, 0.0009295286150195885]
2023-12-07 13:29:54,635	base	INFO	Train Epoch: 4 [10880/12500 (87%)]	Loss: 1.186038
2023-12-07 13:29:54,640	base	INFO	[0.08332765102386475, 1.1027098894119263, 6046, 0.000927990423307029]
2023-12-07 13:30:11,042	base	INFO	Train Epoch: 4 [11040/12500 (88%)]	Loss: 1.190733
2023-12-07 13:30:11,047	base	INFO	[0.0743710994720459, 1.1163616180419922, 6066, 0.0009264598426457334]
2023-12-07 13:30:26,893	base	INFO	Train Epoch: 4 [11200/12500 (90%)]	Loss: 1.098329
2023-12-07 13:30:26,896	base	INFO	[0.07673901319503784, 1.021589994430542, 6086, 0.0009249368104755887]
2023-12-07 13:30:43,026	base	INFO	Train Epoch: 4 [11360/12500 (91%)]	Loss: 1.235046
2023-12-07 13:30:43,028	base	INFO	[0.08441406488418579, 1.1506317853927612, 6106, 0.0009234212649540338]
2023-12-07 13:30:59,028	base	INFO	Train Epoch: 4 [11520/12500 (92%)]	Loss: 1.172022
2023-12-07 13:30:59,031	base	INFO	[0.08860599994659424, 1.0834157466888428, 6126, 0.000921913144945512]
2023-12-07 13:31:15,106	base	INFO	Train Epoch: 4 [11680/12500 (93%)]	Loss: 1.155368
2023-12-07 13:31:15,115	base	INFO	[0.09575307369232178, 1.059614896774292, 6146, 0.0009204123900111125]
2023-12-07 13:31:31,420	base	INFO	Train Epoch: 4 [11840/12500 (95%)]	Loss: 1.221701
2023-12-07 13:31:31,430	base	INFO	[0.09364527463912964, 1.1280556917190552, 6166, 0.0009189189403983976]
2023-12-07 13:31:48,957	base	INFO	Train Epoch: 4 [12000/12500 (96%)]	Loss: 1.080292
2023-12-07 13:31:48,959	base	INFO	[0.08125227689743042, 0.9990401864051819, 6186, 0.0009174327370314101]
2023-12-07 13:32:05,097	base	INFO	Train Epoch: 4 [12160/12500 (97%)]	Loss: 1.120155
2023-12-07 13:32:05,099	base	INFO	[0.07446843385696411, 1.0456868410110474, 6206, 0.000915953721500858]
2023-12-07 13:32:21,447	base	INFO	Train Epoch: 4 [12320/12500 (99%)]	Loss: 1.142330
2023-12-07 13:32:21,449	base	INFO	[0.07734239101409912, 1.064987301826477, 6226, 0.000914481836054473]
2023-12-07 13:32:37,660	base	INFO	Train Epoch: 4 [12480/12500 (100%)]	Loss: 1.114452
2023-12-07 13:32:37,663	base	INFO	[0.07487636804580688, 1.0395759344100952, 6246, 0.000913017023587539]
2023-12-07 13:32:38,888	base	INFO	====> Epoch: 4
2023-12-07 13:32:39,446	base	INFO	Eval Epoch: 4 [0/100 (0%)]	Loss: 1.405972
2023-12-07 13:32:39,447	base	INFO	[0.07641482353210449, 1.3295575380325317]
2023-12-07 13:32:42,142	base	INFO	====> Epoch: 4
2023-12-07 13:32:42,143	base	INFO	Saving model and optimizer state at iteration 4 to ./logs/base/G_4.pdparams
2023-12-07 13:32:44,633	base	INFO	Train Epoch: 5 [0/12500 (0%)]	Loss: 1.122481
2023-12-07 13:32:44,633	base	INFO	[0.09190624952316284, 1.0305745601654053, 6248, 0.0009128709291752768]
2023-12-07 13:33:00,533	base	INFO	Train Epoch: 5 [160/12500 (1%)]	Loss: 1.091952
2023-12-07 13:33:00,542	base	INFO	[0.08229249715805054, 1.0096595287322998, 6268, 0.0009114138317912647]
2023-12-07 13:33:16,695	base	INFO	Train Epoch: 5 [320/12500 (3%)]	Loss: 1.112641
2023-12-07 13:33:16,704	base	INFO	[0.06946921348571777, 1.0431718826293945, 6288, 0.0009099636895333848]
2023-12-07 13:33:32,576	base	INFO	Train Epoch: 5 [480/12500 (4%)]	Loss: 1.164875
2023-12-07 13:33:32,585	base	INFO	[0.09644973278045654, 1.068424940109253, 6308, 0.0009085204472459162]
2023-12-07 13:33:49,568	base	INFO	Train Epoch: 5 [640/12500 (5%)]	Loss: 1.234361
2023-12-07 13:33:49,577	base	INFO	[0.09597951173782349, 1.1383819580078125, 6328, 0.0009070840503835585]
2023-12-07 13:34:05,710	base	INFO	Train Epoch: 5 [800/12500 (6%)]	Loss: 1.102818
2023-12-07 13:34:05,720	base	INFO	[0.06777876615524292, 1.0350395441055298, 6348, 0.000905654445002773]
2023-12-07 13:34:22,581	base	INFO	Train Epoch: 5 [960/12500 (8%)]	Loss: 1.149003
2023-12-07 13:34:22,583	base	INFO	[0.07382732629776001, 1.0751757621765137, 6368, 0.0009042315777532736]
2023-12-07 13:34:38,462	base	INFO	Train Epoch: 5 [1120/12500 (9%)]	Loss: 1.066706
2023-12-07 13:34:38,465	base	INFO	[0.08526086807250977, 0.9814456105232239, 6388, 0.0009028153958696656]
2023-12-07 13:34:54,570	base	INFO	Train Epoch: 5 [1280/12500 (10%)]	Loss: 1.216599
2023-12-07 13:34:54,572	base	INFO	[0.08223021030426025, 1.1343683004379272, 6408, 0.0009014058471632253]
2023-12-07 13:35:10,715	base	INFO	Train Epoch: 5 [1440/12500 (12%)]	Loss: 1.135637
2023-12-07 13:35:10,718	base	INFO	[0.0788375735282898, 1.0567991733551025, 6428, 0.000900002880013824]
2023-12-07 13:35:27,119	base	INFO	Train Epoch: 5 [1600/12500 (13%)]	Loss: 1.155538
2023-12-07 13:35:27,124	base	INFO	[0.06943994760513306, 1.0860978364944458, 6448, 0.0008986064433619868]
2023-12-07 13:35:44,022	base	INFO	Train Epoch: 5 [1760/12500 (14%)]	Loss: 1.072438
2023-12-07 13:35:44,029	base	INFO	[0.06592512130737305, 1.006512999534607, 6468, 0.0008972164867010877]
2023-12-07 13:36:00,980	base	INFO	Train Epoch: 5 [1920/12500 (15%)]	Loss: 1.148857
2023-12-07 13:36:00,983	base	INFO	[0.08185011148452759, 1.067007064819336, 6488, 0.0008958329600696777]
2023-12-07 13:36:17,460	base	INFO	Train Epoch: 5 [2080/12500 (17%)]	Loss: 1.113587
2023-12-07 13:36:17,465	base	INFO	[0.06987929344177246, 1.0437079668045044, 6508, 0.0008944558140439413]
2023-12-07 13:36:33,472	base	INFO	Train Epoch: 5 [2240/12500 (18%)]	Loss: 1.076053
2023-12-07 13:36:33,481	base	INFO	[0.07490211725234985, 1.0011509656906128, 6528, 0.0008930849997302811]
2023-12-07 13:36:49,538	base	INFO	Train Epoch: 5 [2400/12500 (19%)]	Loss: 1.155868
2023-12-07 13:36:49,547	base	INFO	[0.07345610857009888, 1.082411766052246, 6548, 0.000891720468758027]
2023-12-07 13:37:06,153	base	INFO	Train Epoch: 5 [2560/12500 (20%)]	Loss: 1.183177
2023-12-07 13:37:06,155	base	INFO	[0.08917808532714844, 1.0939990282058716, 6568, 0.0008903621732722671]
2023-12-07 13:37:22,511	base	INFO	Train Epoch: 5 [2720/12500 (22%)]	Loss: 1.197136
2023-12-07 13:37:22,513	base	INFO	[0.07371139526367188, 1.123424768447876, 6588, 0.0008890100659267984]
2023-12-07 13:37:38,956	base	INFO	Train Epoch: 5 [2880/12500 (23%)]	Loss: 1.103900
2023-12-07 13:37:38,958	base	INFO	[0.08137333393096924, 1.0225266218185425, 6608, 0.0008876640998771954]
2023-12-07 13:37:56,051	base	INFO	Train Epoch: 5 [3040/12500 (24%)]	Loss: 1.084627
2023-12-07 13:37:56,053	base	INFO	[0.07330971956253052, 1.0113171339035034, 6628, 0.0008863242287739937]
2023-12-07 13:38:12,282	base	INFO	Train Epoch: 5 [3200/12500 (26%)]	Loss: 1.167030
2023-12-07 13:38:12,285	base	INFO	[0.09035933017730713, 1.0766708850860596, 6648, 0.0008849904067559858]
2023-12-07 13:38:29,016	base	INFO	Train Epoch: 5 [3360/12500 (27%)]	Loss: 1.154348
2023-12-07 13:38:29,019	base	INFO	[0.08178621530532837, 1.0725618600845337, 6668, 0.0008836625884436278]
2023-12-07 13:38:45,163	base	INFO	Train Epoch: 5 [3520/12500 (28%)]	Loss: 1.137413
2023-12-07 13:38:45,165	base	INFO	[0.07851970195770264, 1.0588934421539307, 6688, 0.0008823407289325556]
2023-12-07 13:39:01,469	base	INFO	Train Epoch: 5 [3680/12500 (29%)]	Loss: 1.093687
2023-12-07 13:39:01,477	base	INFO	[0.075897216796875, 1.0177901983261108, 6708, 0.0008810247837872057]
2023-12-07 13:39:17,393	base	INFO	Train Epoch: 5 [3840/12500 (31%)]	Loss: 1.194994
2023-12-07 13:39:17,402	base	INFO	[0.08448421955108643, 1.1105097532272339, 6728, 0.0008797147090345418]
2023-12-07 13:39:33,235	base	INFO	Train Epoch: 5 [4000/12500 (32%)]	Loss: 1.154743
2023-12-07 13:39:33,245	base	INFO	[0.09788137674331665, 1.0568617582321167, 6748, 0.0008784104611578832]
2023-12-07 13:39:51,189	base	INFO	Train Epoch: 5 [4160/12500 (33%)]	Loss: 1.058041
2023-12-07 13:39:51,190	base	INFO	[0.07414889335632324, 0.9838919043540955, 6768, 0.000877111997090833]
2023-12-07 13:40:07,311	base	INFO	Train Epoch: 5 [4320/12500 (35%)]	Loss: 1.100775
2023-12-07 13:40:07,313	base	INFO	[0.08190703392028809, 1.01886785030365, 6788, 0.0008758192742113065]
2023-12-07 13:40:23,182	base	INFO	Train Epoch: 5 [4480/12500 (36%)]	Loss: 1.177507
2023-12-07 13:40:23,184	base	INFO	[0.0703439712524414, 1.1071630716323853, 6808, 0.000874532250335653]
2023-12-07 13:40:39,149	base	INFO	Train Epoch: 5 [4640/12500 (37%)]	Loss: 1.135224
2023-12-07 13:40:39,151	base	INFO	[0.07860070466995239, 1.056622862815857, 6828, 0.0008732508837128764]
2023-12-07 13:40:55,440	base	INFO	Train Epoch: 5 [4800/12500 (38%)]	Loss: 1.160977
2023-12-07 13:40:55,442	base	INFO	[0.07588750123977661, 1.085089087486267, 6848, 0.0008719751330189446]
2023-12-07 13:41:11,465	base	INFO	Train Epoch: 5 [4960/12500 (40%)]	Loss: 1.054758
2023-12-07 13:41:11,471	base	INFO	[0.08253693580627441, 0.9722208976745605, 6868, 0.0008707049573511935]
2023-12-07 13:41:27,526	base	INFO	Train Epoch: 5 [5120/12500 (41%)]	Loss: 1.133377
2023-12-07 13:41:27,530	base	INFO	[0.06962233781814575, 1.0637545585632324, 6888, 0.0008694403162228176]
2023-12-07 13:41:43,718	base	INFO	Train Epoch: 5 [5280/12500 (42%)]	Loss: 1.092330
2023-12-07 13:41:43,722	base	INFO	[0.06424140930175781, 1.0280883312225342, 6908, 0.0008681811695574511]
2023-12-07 13:42:00,646	base	INFO	Train Epoch: 5 [5440/12500 (44%)]	Loss: 1.186585
2023-12-07 13:42:00,648	base	INFO	[0.07002109289169312, 1.1165642738342285, 6928, 0.0008669274776838322]
2023-12-07 13:42:16,792	base	INFO	Train Epoch: 5 [5600/12500 (45%)]	Loss: 1.164507
2023-12-07 13:42:16,801	base	INFO	[0.056404709815979004, 1.1081022024154663, 6948, 0.0008656792013305546]
2023-12-07 13:42:33,534	base	INFO	Train Epoch: 5 [5760/12500 (46%)]	Loss: 1.084553
2023-12-07 13:42:33,535	base	INFO	[0.06720107793807983, 1.0173516273498535, 6968, 0.0008644363016208997]
2023-12-07 13:42:49,614	base	INFO	Train Epoch: 5 [5920/12500 (47%)]	Loss: 1.185280
2023-12-07 13:42:49,615	base	INFO	[0.07013243436813354, 1.1151479482650757, 6988, 0.0008631987400677517]
2023-12-07 13:43:05,649	base	INFO	Train Epoch: 5 [6080/12500 (49%)]	Loss: 1.133556
2023-12-07 13:43:05,652	base	INFO	[0.07931685447692871, 1.0542387962341309, 7008, 0.000861966478568592]
2023-12-07 13:43:22,118	base	INFO	Train Epoch: 5 [6240/12500 (50%)]	Loss: 1.177532
2023-12-07 13:43:22,121	base	INFO	[0.07593613862991333, 1.1015958786010742, 7028, 0.0008607394794005717]
2023-12-07 13:43:37,956	base	INFO	Train Epoch: 5 [6400/12500 (51%)]	Loss: 1.041901
2023-12-07 13:43:37,958	base	INFO	[0.07912391424179077, 0.9627771973609924, 7048, 0.0008595177052156611]
2023-12-07 13:43:54,114	base	INFO	Train Epoch: 5 [6560/12500 (52%)]	Loss: 1.107947
2023-12-07 13:43:54,127	base	INFO	[0.08524781465530396, 1.022699236869812, 7068, 0.0008583011190358758]
2023-12-07 13:44:10,877	base	INFO	Train Epoch: 5 [6720/12500 (54%)]	Loss: 1.127893
2023-12-07 13:44:10,885	base	INFO	[0.08429604768753052, 1.0435969829559326, 7088, 0.000857089684248575]
2023-12-07 13:44:27,356	base	INFO	Train Epoch: 5 [6880/12500 (55%)]	Loss: 1.147404
2023-12-07 13:44:27,359	base	INFO	[0.06790131330490112, 1.0795031785964966, 7108, 0.0008558833646018344]
2023-12-07 13:44:43,509	base	INFO	Train Epoch: 5 [7040/12500 (56%)]	Loss: 1.099336
2023-12-07 13:44:43,513	base	INFO	[0.07126975059509277, 1.028066635131836, 7128, 0.0008546821241998893]
2023-12-07 13:44:59,610	base	INFO	Train Epoch: 5 [7200/12500 (58%)]	Loss: 1.166045
2023-12-07 13:44:59,620	base	INFO	[0.05647379159927368, 1.1095712184906006, 7148, 0.0008534859274986485]
2023-12-07 13:45:16,029	base	INFO	Train Epoch: 5 [7360/12500 (59%)]	Loss: 1.188448
2023-12-07 13:45:16,031	base	INFO	[0.07176226377487183, 1.1166861057281494, 7168, 0.0008522947393012773]
2023-12-07 13:45:31,971	base	INFO	Train Epoch: 5 [7520/12500 (60%)]	Loss: 1.107215
2023-12-07 13:45:31,973	base	INFO	[0.06042593717575073, 1.046789288520813, 7188, 0.0008511085247538468]
2023-12-07 13:45:48,284	base	INFO	Train Epoch: 5 [7680/12500 (61%)]	Loss: 1.023488
2023-12-07 13:45:48,286	base	INFO	[0.06814587116241455, 0.9553422331809998, 7208, 0.0008499272493410513]
2023-12-07 13:46:04,833	base	INFO	Train Epoch: 5 [7840/12500 (63%)]	Loss: 1.139311
2023-12-07 13:46:04,836	base	INFO	[0.0783681869506836, 1.0609432458877563, 7228, 0.0008487508788819901]
2023-12-07 13:46:21,014	base	INFO	Train Epoch: 5 [8000/12500 (64%)]	Loss: 1.142585
2023-12-07 13:46:21,016	base	INFO	[0.07905793190002441, 1.0635273456573486, 7248, 0.0008475793795260129]
2023-12-07 13:46:37,148	base	INFO	Train Epoch: 5 [8160/12500 (65%)]	Loss: 1.107911
2023-12-07 13:46:37,151	base	INFO	[0.06509590148925781, 1.0428154468536377, 7268, 0.0008464127177486292]
2023-12-07 13:46:53,656	base	INFO	Train Epoch: 5 [8320/12500 (67%)]	Loss: 1.142780
2023-12-07 13:46:53,658	base	INFO	[0.064960777759552, 1.0778193473815918, 7288, 0.0008452508603474786]
2023-12-07 13:47:09,589	base	INFO	Train Epoch: 5 [8480/12500 (68%)]	Loss: 1.081998
2023-12-07 13:47:09,593	base	INFO	[0.06477952003479004, 1.0172184705734253, 7308, 0.0008440937744383615]
2023-12-07 13:47:25,568	base	INFO	Train Epoch: 5 [8640/12500 (69%)]	Loss: 1.088956
2023-12-07 13:47:25,574	base	INFO	[0.08176863193511963, 1.0071877241134644, 7328, 0.0008429414274513312]
2023-12-07 13:47:41,552	base	INFO	Train Epoch: 5 [8800/12500 (70%)]	Loss: 1.136070
2023-12-07 13:47:41,563	base	INFO	[0.07423138618469238, 1.0618385076522827, 7348, 0.0008417937871268423]
2023-12-07 13:47:58,862	base	INFO	Train Epoch: 5 [8960/12500 (72%)]	Loss: 1.106543
2023-12-07 13:47:58,865	base	INFO	[0.07691657543182373, 1.0296266078948975, 7368, 0.0008406508215119575]
2023-12-07 13:48:15,812	base	INFO	Train Epoch: 5 [9120/12500 (73%)]	Loss: 1.085725
2023-12-07 13:48:15,814	base	INFO	[0.07493698596954346, 1.0107884407043457, 7388, 0.0008395124989566119]
2023-12-07 13:48:32,012	base	INFO	Train Epoch: 5 [9280/12500 (74%)]	Loss: 1.121133
2023-12-07 13:48:32,014	base	INFO	[0.07738304138183594, 1.0437499284744263, 7408, 0.0008383787881099309]
2023-12-07 13:48:48,620	base	INFO	Train Epoch: 5 [9440/12500 (76%)]	Loss: 1.143379
2023-12-07 13:48:48,622	base	INFO	[0.06121480464935303, 1.0821646451950073, 7428, 0.0008372496579166046]
2023-12-07 13:49:04,794	base	INFO	Train Epoch: 5 [9600/12500 (77%)]	Loss: 1.157839
2023-12-07 13:49:04,796	base	INFO	[0.0658990740776062, 1.0919398069381714, 7448, 0.0008361250776133138]
2023-12-07 13:49:20,978	base	INFO	Train Epoch: 5 [9760/12500 (78%)]	Loss: 1.137582
2023-12-07 13:49:20,979	base	INFO	[0.06811511516571045, 1.0694669485092163, 7468, 0.0008350050167252107]
2023-12-07 13:49:36,826	base	INFO	Train Epoch: 5 [9920/12500 (79%)]	Loss: 1.060609
2023-12-07 13:49:36,828	base	INFO	[0.07224667072296143, 0.9883620142936707, 7488, 0.0008338894450624493]
2023-12-07 13:49:52,658	base	INFO	Train Epoch: 5 [10080/12500 (81%)]	Loss: 1.119892
2023-12-07 13:49:52,662	base	INFO	[0.06592053174972534, 1.0539714097976685, 7508, 0.0008327783327167686]
2023-12-07 13:50:09,834	base	INFO	Train Epoch: 5 [10240/12500 (82%)]	Loss: 1.089379
2023-12-07 13:50:09,843	base	INFO	[0.06849849224090576, 1.0208805799484253, 7528, 0.0008316716500581241]
2023-12-07 13:50:26,552	base	INFO	Train Epoch: 5 [10400/12500 (83%)]	Loss: 1.134615
2023-12-07 13:50:26,562	base	INFO	[0.07941192388534546, 1.0552030801773071, 7548, 0.0008305693677313692]
2023-12-07 13:50:43,489	base	INFO	Train Epoch: 5 [10560/12500 (85%)]	Loss: 1.007757
2023-12-07 13:50:43,489	base	INFO	[0.07489728927612305, 0.9328599572181702, 7568, 0.0008294714566529854]
2023-12-07 13:51:00,533	base	INFO	Train Epoch: 5 [10720/12500 (86%)]	Loss: 1.047727
2023-12-07 13:51:00,535	base	INFO	[0.06790226697921753, 0.9798250198364258, 7588, 0.0008283778880078584]
2023-12-07 13:51:16,610	base	INFO	Train Epoch: 5 [10880/12500 (87%)]	Loss: 1.139174
2023-12-07 13:51:16,613	base	INFO	[0.07255864143371582, 1.0666154623031616, 7608, 0.0008272886332461023]
2023-12-07 13:51:32,978	base	INFO	Train Epoch: 5 [11040/12500 (88%)]	Loss: 1.145081
2023-12-07 13:51:32,981	base	INFO	[0.062446415424346924, 1.0826345682144165, 7628, 0.0008262036640799289]
2023-12-07 13:51:49,169	base	INFO	Train Epoch: 5 [11200/12500 (90%)]	Loss: 1.069196
2023-12-07 13:51:49,173	base	INFO	[0.06245821714401245, 1.006738305091858, 7648, 0.0008251229524805618]
2023-12-07 13:52:06,199	base	INFO	Train Epoch: 5 [11360/12500 (91%)]	Loss: 1.137284
2023-12-07 13:52:06,205	base	INFO	[0.07089942693710327, 1.0663845539093018, 7668, 0.000824046470675196]
2023-12-07 13:52:22,230	base	INFO	Train Epoch: 5 [11520/12500 (92%)]	Loss: 1.181942
2023-12-07 13:52:22,240	base	INFO	[0.07429474592208862, 1.1076470613479614, 7688, 0.0008229741911439994]
2023-12-07 13:52:38,511	base	INFO	Train Epoch: 5 [11680/12500 (93%)]	Loss: 1.139695
2023-12-07 13:52:38,518	base	INFO	[0.08072477579116821, 1.0589706897735596, 7708, 0.000821906086617158]
2023-12-07 13:52:54,716	base	INFO	Train Epoch: 5 [11840/12500 (95%)]	Loss: 1.186297
2023-12-07 13:52:54,725	base	INFO	[0.07924973964691162, 1.1070468425750732, 7728, 0.0008208421300719633]
2023-12-07 13:53:10,932	base	INFO	Train Epoch: 5 [12000/12500 (96%)]	Loss: 1.120195
2023-12-07 13:53:10,941	base	INFO	[0.06436383724212646, 1.0558315515518188, 7748, 0.0008197822947299412]
2023-12-07 13:53:27,685	base	INFO	Train Epoch: 5 [12160/12500 (97%)]	Loss: 1.147533
2023-12-07 13:53:27,687	base	INFO	[0.0587422251701355, 1.0887904167175293, 7768, 0.0008187265540540201]
2023-12-07 13:53:43,653	base	INFO	Train Epoch: 5 [12320/12500 (99%)]	Loss: 1.086683
2023-12-07 13:53:43,654	base	INFO	[0.06406033039093018, 1.0226225852966309, 7788, 0.0008176748817457412]
2023-12-07 13:53:59,846	base	INFO	Train Epoch: 5 [12480/12500 (100%)]	Loss: 1.058864
2023-12-07 13:53:59,849	base	INFO	[0.05808115005493164, 1.0007826089859009, 7808, 0.0008166272517425064]
2023-12-07 13:54:01,058	base	INFO	====> Epoch: 5
2023-12-07 13:54:01,668	base	INFO	Eval Epoch: 5 [0/100 (0%)]	Loss: 1.232286
2023-12-07 13:54:01,669	base	INFO	[0.06174951791763306, 1.1705361604690552]
2023-12-07 13:54:04,342	base	INFO	====> Epoch: 5
2023-12-07 13:54:04,342	base	INFO	Saving model and optimizer state at iteration 5 to ./logs/base/G_5.pdparams
2023-12-07 13:54:07,891	base	INFO	Train Epoch: 6 [0/12500 (0%)]	Loss: 1.112213
2023-12-07 13:54:07,892	base	INFO	[0.07598364353179932, 1.0362298488616943, 7810, 0.0008165227100725214]
2023-12-07 13:54:23,589	base	INFO	Train Epoch: 6 [160/12500 (1%)]	Loss: 1.119274
2023-12-07 13:54:23,597	base	INFO	[0.06577849388122559, 1.0534957647323608, 7830, 0.0008154794967807166]
2023-12-07 13:54:39,242	base	INFO	Train Epoch: 6 [320/12500 (3%)]	Loss: 1.046765
2023-12-07 13:54:39,250	base	INFO	[0.054503023624420166, 0.9922618269920349, 7850, 0.0008144402718182063]
2023-12-07 13:54:55,221	base	INFO	Train Epoch: 6 [480/12500 (4%)]	Loss: 1.117616
2023-12-07 13:54:55,224	base	INFO	[0.08248311281204224, 1.035132884979248, 7870, 0.0008134050098364899]
2023-12-07 13:55:11,392	base	INFO	Train Epoch: 6 [640/12500 (5%)]	Loss: 1.113530
2023-12-07 13:55:11,402	base	INFO	[0.08032053709030151, 1.033209204673767, 7890, 0.0008123736857120442]
2023-12-07 13:55:27,203	base	INFO	Train Epoch: 6 [800/12500 (6%)]	Loss: 1.069351
2023-12-07 13:55:27,213	base	INFO	[0.05183929204940796, 1.0175117254257202, 7910, 0.0008113462745437628]
2023-12-07 13:55:43,261	base	INFO	Train Epoch: 6 [960/12500 (8%)]	Loss: 1.092484
2023-12-07 13:55:43,272	base	INFO	[0.058152735233306885, 1.0343314409255981, 7930, 0.0008103227516504312]
2023-12-07 13:55:59,715	base	INFO	Train Epoch: 6 [1120/12500 (9%)]	Loss: 1.040754
2023-12-07 13:55:59,716	base	INFO	[0.06815242767333984, 0.9726016521453857, 7950, 0.0008093030925682353]
2023-12-07 13:56:16,678	base	INFO	Train Epoch: 6 [1280/12500 (10%)]	Loss: 1.176009
2023-12-07 13:56:16,681	base	INFO	[0.06584310531616211, 1.1101659536361694, 7970, 0.0008082872730483068]
2023-12-07 13:56:32,783	base	INFO	Train Epoch: 6 [1440/12500 (12%)]	Loss: 1.102977
2023-12-07 13:56:32,786	base	INFO	[0.06405311822891235, 1.0389233827590942, 7990, 0.0008072752690543005]
2023-12-07 13:56:48,525	base	INFO	Train Epoch: 6 [1600/12500 (13%)]	Loss: 1.048601
2023-12-07 13:56:48,528	base	INFO	[0.05253124237060547, 0.9960697889328003, 8010, 0.0008062670567600055]
2023-12-07 13:57:04,509	base	INFO	Train Epoch: 6 [1760/12500 (14%)]	Loss: 1.044347
2023-12-07 13:57:04,511	base	INFO	[0.04488980770111084, 0.9994568228721619, 8030, 0.0008052626125469893]
2023-12-07 13:57:20,726	base	INFO	Train Epoch: 6 [1920/12500 (15%)]	Loss: 1.129170
2023-12-07 13:57:20,734	base	INFO	[0.0612601637840271, 1.0679097175598145, 8050, 0.0008042619130022738]
2023-12-07 13:57:37,004	base	INFO	Train Epoch: 6 [2080/12500 (17%)]	Loss: 1.095199
2023-12-07 13:57:37,013	base	INFO	[0.05008554458618164, 1.045113444328308, 8070, 0.0008032649349160434]
2023-12-07 13:57:52,789	base	INFO	Train Epoch: 6 [2240/12500 (18%)]	Loss: 1.094386
2023-12-07 13:57:52,799	base	INFO	[0.05598616600036621, 1.0383999347686768, 8090, 0.0008022716552793836]
2023-12-07 13:58:08,961	base	INFO	Train Epoch: 6 [2400/12500 (19%)]	Loss: 1.074334
2023-12-07 13:58:08,969	base	INFO	[0.055595219135284424, 1.018738865852356, 8110, 0.0008012820512820513]
2023-12-07 13:58:25,858	base	INFO	Train Epoch: 6 [2560/12500 (20%)]	Loss: 1.102696
2023-12-07 13:58:25,866	base	INFO	[0.07021236419677734, 1.0324832201004028, 8130, 0.0008002961003102735]
2023-12-07 13:58:42,994	base	INFO	Train Epoch: 6 [2720/12500 (22%)]	Loss: 1.126739
2023-12-07 13:58:42,996	base	INFO	[0.05484139919281006, 1.0718978643417358, 8150, 0.0007993137799445785]
2023-12-07 13:58:59,171	base	INFO	Train Epoch: 6 [2880/12500 (23%)]	Loss: 1.101154
2023-12-07 13:58:59,173	base	INFO	[0.06361782550811768, 1.037536382675171, 8170, 0.0007983350679576535]
2023-12-07 13:59:14,640	base	INFO	Train Epoch: 6 [3040/12500 (24%)]	Loss: 1.075694
2023-12-07 13:59:14,642	base	INFO	[0.05625349283218384, 1.019440770149231, 8190, 0.0007973599423122325]
2023-12-07 13:59:30,600	base	INFO	Train Epoch: 6 [3200/12500 (26%)]	Loss: 1.099467
2023-12-07 13:59:30,604	base	INFO	[0.07250189781188965, 1.0269649028778076, 8210, 0.0007963883811590122]
2023-12-07 13:59:46,729	base	INFO	Train Epoch: 6 [3360/12500 (27%)]	Loss: 1.081326
2023-12-07 13:59:46,732	base	INFO	[0.06765216588973999, 1.013674020767212, 8230, 0.0007954203628345963]
2023-12-07 14:00:03,109	base	INFO	Train Epoch: 6 [3520/12500 (28%)]	Loss: 1.054571
2023-12-07 14:00:03,111	base	INFO	[0.06352406740188599, 0.9910467267036438, 8250, 0.0007944558658594657]
2023-12-07 14:00:19,956	base	INFO	Train Epoch: 6 [3680/12500 (29%)]	Loss: 1.063133
2023-12-07 14:00:19,960	base	INFO	[0.06209385395050049, 1.0010387897491455, 8270, 0.0007934948689359775]
2023-12-07 14:00:35,981	base	INFO	Train Epoch: 6 [3840/12500 (31%)]	Loss: 1.054655
2023-12-07 14:00:35,983	base	INFO	[0.0690266489982605, 0.9856287240982056, 8290, 0.000792537350946389]
2023-12-07 14:00:52,350	base	INFO	Train Epoch: 6 [4000/12500 (32%)]	Loss: 1.024735
2023-12-07 14:00:52,355	base	INFO	[0.08459454774856567, 0.9401401877403259, 8310, 0.0007915832909509096]
2023-12-07 14:01:08,307	base	INFO	Train Epoch: 6 [4160/12500 (33%)]	Loss: 1.066384
2023-12-07 14:01:08,309	base	INFO	[0.0600544810295105, 1.0063291788101196, 8330, 0.0007906326681857767]
2023-12-07 14:01:24,414	base	INFO	Train Epoch: 6 [4320/12500 (35%)]	Loss: 1.010541
2023-12-07 14:01:24,415	base	INFO	[0.0662723183631897, 0.9442691802978516, 8350, 0.0007896854620613576]
2023-12-07 14:01:40,434	base	INFO	Train Epoch: 6 [4480/12500 (36%)]	Loss: 1.163704
2023-12-07 14:01:40,435	base	INFO	[0.05437135696411133, 1.1093329191207886, 8370, 0.0007887416521602775]
2023-12-07 14:01:56,312	base	INFO	Train Epoch: 6 [4640/12500 (37%)]	Loss: 1.110925
2023-12-07 14:01:56,314	base	INFO	[0.06447267532348633, 1.046452283859253, 8390, 0.0007878012182355697]
2023-12-07 14:02:12,278	base	INFO	Train Epoch: 6 [4800/12500 (38%)]	Loss: 1.115191
2023-12-07 14:02:12,281	base	INFO	[0.062020063400268555, 1.0531713962554932, 8410, 0.0007868641402088521]
2023-12-07 14:02:29,200	base	INFO	Train Epoch: 6 [4960/12500 (40%)]	Loss: 0.988363
2023-12-07 14:02:29,202	base	INFO	[0.0674217939376831, 0.920941174030304, 8430, 0.0007859303981685263]
2023-12-07 14:02:45,483	base	INFO	Train Epoch: 6 [5120/12500 (41%)]	Loss: 1.130120
2023-12-07 14:02:45,490	base	INFO	[0.054904818534851074, 1.0752149820327759, 8450, 0.0007849999723680014]
2023-12-07 14:03:01,796	base	INFO	Train Epoch: 6 [5280/12500 (42%)]	Loss: 1.054135
2023-12-07 14:03:01,802	base	INFO	[0.0510101318359375, 1.003124475479126, 8470, 0.0007840728432239389]
2023-12-07 14:03:17,809	base	INFO	Train Epoch: 6 [5440/12500 (44%)]	Loss: 1.157043
2023-12-07 14:03:17,811	base	INFO	[0.05580335855484009, 1.1012393236160278, 8490, 0.0007831489913145224]
2023-12-07 14:03:33,989	base	INFO	Train Epoch: 6 [5600/12500 (45%)]	Loss: 1.001653
2023-12-07 14:03:33,990	base	INFO	[0.04218417406082153, 0.9594689011573792, 8510, 0.0007822283973777482]
2023-12-07 14:03:50,177	base	INFO	Train Epoch: 6 [5760/12500 (46%)]	Loss: 1.066589
2023-12-07 14:03:50,187	base	INFO	[0.05276542901992798, 1.0138235092163086, 8530, 0.0007813110423097387]
2023-12-07 14:04:06,814	base	INFO	Train Epoch: 6 [5920/12500 (47%)]	Loss: 1.112908
2023-12-07 14:04:06,817	base	INFO	[0.05693179368972778, 1.055976152420044, 8550, 0.0007803969071630778]
2023-12-07 14:04:23,786	base	INFO	Train Epoch: 6 [6080/12500 (49%)]	Loss: 1.090479
2023-12-07 14:04:23,788	base	INFO	[0.06633371114730835, 1.024145483970642, 8570, 0.0007794859731451662]
2023-12-07 14:04:39,694	base	INFO	Train Epoch: 6 [6240/12500 (50%)]	Loss: 1.092720
2023-12-07 14:04:39,694	base	INFO	[0.06232482194900513, 1.0303955078125, 8590, 0.0007785782216165999]
2023-12-07 14:04:55,626	base	INFO	Train Epoch: 6 [6400/12500 (51%)]	Loss: 1.006720
2023-12-07 14:04:55,629	base	INFO	[0.06435680389404297, 0.9423633217811584, 8610, 0.0007776736340895671]
2023-12-07 14:05:11,631	base	INFO	Train Epoch: 6 [6560/12500 (52%)]	Loss: 1.111550
2023-12-07 14:05:11,633	base	INFO	[0.0717887282371521, 1.0397611856460571, 8630, 0.0007767721922262681]
2023-12-07 14:05:27,626	base	INFO	Train Epoch: 6 [6720/12500 (54%)]	Loss: 1.126700
2023-12-07 14:05:27,631	base	INFO	[0.07092392444610596, 1.0557756423950195, 8650, 0.0007758738778373527]
2023-12-07 14:05:43,621	base	INFO	Train Epoch: 6 [6880/12500 (55%)]	Loss: 1.100774
2023-12-07 14:05:43,631	base	INFO	[0.05488067865371704, 1.0458929538726807, 8670, 0.0007749786728803794]
2023-12-07 14:05:59,595	base	INFO	Train Epoch: 6 [7040/12500 (56%)]	Loss: 1.079135
2023-12-07 14:05:59,604	base	INFO	[0.05906784534454346, 1.0200674533843994, 8690, 0.0007740865594582932]
2023-12-07 14:06:15,952	base	INFO	Train Epoch: 6 [7200/12500 (58%)]	Loss: 1.059198
2023-12-07 14:06:15,960	base	INFO	[0.04127877950668335, 1.0179189443588257, 8710, 0.0007731975198179223]
2023-12-07 14:06:32,805	base	INFO	Train Epoch: 6 [7360/12500 (59%)]	Loss: 1.161258
2023-12-07 14:06:32,815	base	INFO	[0.060618460178375244, 1.100639820098877, 8730, 0.0007723115363484955]
2023-12-07 14:06:49,310	base	INFO	Train Epoch: 6 [7520/12500 (60%)]	Loss: 1.109700
2023-12-07 14:06:49,311	base	INFO	[0.04735982418060303, 1.0623401403427124, 8750, 0.0007714285915801757]
2023-12-07 14:07:05,552	base	INFO	Train Epoch: 6 [7680/12500 (61%)]	Loss: 1.040725
2023-12-07 14:07:05,553	base	INFO	[0.053560733795166016, 0.9871647357940674, 8770, 0.0007705486681826136]
2023-12-07 14:07:21,385	base	INFO	Train Epoch: 6 [7840/12500 (63%)]	Loss: 1.057198
2023-12-07 14:07:21,387	base	INFO	[0.06750178337097168, 0.9896959662437439, 8790, 0.0007696717489635194]
2023-12-07 14:07:37,122	base	INFO	Train Epoch: 6 [8000/12500 (64%)]	Loss: 1.163211
2023-12-07 14:07:37,124	base	INFO	[0.06856739521026611, 1.0946431159973145, 8810, 0.0007687978168672513]
2023-12-07 14:07:53,218	base	INFO	Train Epoch: 6 [8160/12500 (65%)]	Loss: 1.094747
2023-12-07 14:07:53,221	base	INFO	[0.051635563373565674, 1.043110966682434, 8830, 0.0007679268549734225]
2023-12-07 14:08:09,361	base	INFO	Train Epoch: 6 [8320/12500 (67%)]	Loss: 1.096123
2023-12-07 14:08:09,365	base	INFO	[0.052606940269470215, 1.0435162782669067, 8850, 0.0007670588464955255]
2023-12-07 14:08:26,190	base	INFO	Train Epoch: 6 [8480/12500 (68%)]	Loss: 1.043469
2023-12-07 14:08:26,199	base	INFO	[0.05133908987045288, 0.9921303987503052, 8870, 0.0007661937747795728]
2023-12-07 14:08:42,088	base	INFO	Train Epoch: 6 [8640/12500 (69%)]	Loss: 1.048537
2023-12-07 14:08:42,097	base	INFO	[0.06840342283248901, 0.9801339507102966, 8890, 0.0007653316233027552]
2023-12-07 14:08:58,022	base	INFO	Train Epoch: 6 [8800/12500 (70%)]	Loss: 1.116240
2023-12-07 14:08:58,031	base	INFO	[0.061496078968048096, 1.054743766784668, 8910, 0.000764472375672116]
2023-12-07 14:09:14,148	base	INFO	Train Epoch: 6 [8960/12500 (72%)]	Loss: 1.109850
2023-12-07 14:09:14,157	base	INFO	[0.06421846151351929, 1.0456315279006958, 8930, 0.0007636160156232422]
2023-12-07 14:09:30,802	base	INFO	Train Epoch: 6 [9120/12500 (73%)]	Loss: 1.122348
2023-12-07 14:09:30,804	base	INFO	[0.062741219997406, 1.0596067905426025, 8950, 0.0007627625270189714]
2023-12-07 14:09:47,057	base	INFO	Train Epoch: 6 [9280/12500 (74%)]	Loss: 1.065497
2023-12-07 14:09:47,060	base	INFO	[0.06539112329483032, 1.0001060962677002, 8970, 0.0007619118938481138]
2023-12-07 14:10:03,014	base	INFO	Train Epoch: 6 [9440/12500 (76%)]	Loss: 1.070183
2023-12-07 14:10:03,016	base	INFO	[0.0485571026802063, 1.0216261148452759, 8990, 0.0007610641002241922]
2023-12-07 14:10:18,924	base	INFO	Train Epoch: 6 [9600/12500 (77%)]	Loss: 1.108395
2023-12-07 14:10:18,927	base	INFO	[0.053602397441864014, 1.0547925233840942, 9010, 0.0007602191303841943]
2023-12-07 14:10:35,856	base	INFO	Train Epoch: 6 [9760/12500 (78%)]	Loss: 1.076530
2023-12-07 14:10:35,858	base	INFO	[0.056411802768707275, 1.0201185941696167, 9030, 0.0007593769686873431]
2023-12-07 14:10:51,815	base	INFO	Train Epoch: 6 [9920/12500 (79%)]	Loss: 1.018346
2023-12-07 14:10:51,819	base	INFO	[0.0586819052696228, 0.959664523601532, 9050, 0.0007585375996138796]
2023-12-07 14:11:07,539	base	INFO	Train Epoch: 6 [10080/12500 (81%)]	Loss: 1.010258
2023-12-07 14:11:07,541	base	INFO	[0.053608477115631104, 0.9566492438316345, 9070, 0.0007577010077638623]
2023-12-07 14:11:23,623	base	INFO	Train Epoch: 6 [10240/12500 (82%)]	Loss: 1.032235
2023-12-07 14:11:23,631	base	INFO	[0.05750906467437744, 0.9747255444526672, 9090, 0.0007568671778559807]
2023-12-07 14:11:39,820	base	INFO	Train Epoch: 6 [10400/12500 (83%)]	Loss: 1.090466
2023-12-07 14:11:39,823	base	INFO	[0.06919342279434204, 1.0212723016738892, 9110, 0.0007560360947263821]
2023-12-07 14:11:55,843	base	INFO	Train Epoch: 6 [10560/12500 (85%)]	Loss: 1.076428
2023-12-07 14:11:55,852	base	INFO	[0.06509244441986084, 1.0113351345062256, 9130, 0.0007552077433275143]
2023-12-07 14:12:12,436	base	INFO	Train Epoch: 6 [10720/12500 (86%)]	Loss: 0.996028
2023-12-07 14:12:12,436	base	INFO	[0.055268168449401855, 0.9407603144645691, 9150, 0.0007543821087269806]
2023-12-07 14:12:28,888	base	INFO	Train Epoch: 6 [10880/12500 (87%)]	Loss: 1.124394
2023-12-07 14:12:28,890	base	INFO	[0.06097698211669922, 1.063416600227356, 9170, 0.0007535591761064094]
2023-12-07 14:12:44,992	base	INFO	Train Epoch: 6 [11040/12500 (88%)]	Loss: 1.122784
2023-12-07 14:12:44,995	base	INFO	[0.05091029405593872, 1.0718741416931152, 9190, 0.0007527389307603376]
2023-12-07 14:13:00,782	base	INFO	Train Epoch: 6 [11200/12500 (90%)]	Loss: 1.056879
2023-12-07 14:13:00,784	base	INFO	[0.05138885974884033, 1.0054900646209717, 9210, 0.0007519213580951061]
2023-12-07 14:13:16,986	base	INFO	Train Epoch: 6 [11360/12500 (91%)]	Loss: 1.119972
2023-12-07 14:13:16,988	base	INFO	[0.058738112449645996, 1.0612343549728394, 9230, 0.0007511064436277701]
2023-12-07 14:13:33,066	base	INFO	Train Epoch: 6 [11520/12500 (92%)]	Loss: 1.106287
2023-12-07 14:13:33,068	base	INFO	[0.06301158666610718, 1.0432754755020142, 9250, 0.0007502941729850205]
2023-12-07 14:13:48,831	base	INFO	Train Epoch: 6 [11680/12500 (93%)]	Loss: 1.137919
2023-12-07 14:13:48,839	base	INFO	[0.06948709487915039, 1.0684316158294678, 9270, 0.0007494845319021204]
2023-12-07 14:14:04,622	base	INFO	Train Epoch: 6 [11840/12500 (95%)]	Loss: 1.192716
2023-12-07 14:14:04,624	base	INFO	[0.06882256269454956, 1.1238932609558105, 9290, 0.000748677506221852]
2023-12-07 14:14:21,009	base	INFO	Train Epoch: 6 [12000/12500 (96%)]	Loss: 1.136881
2023-12-07 14:14:21,020	base	INFO	[0.053505122661590576, 1.0833754539489746, 9310, 0.0007478730818934772]
2023-12-07 14:14:37,726	base	INFO	Train Epoch: 6 [12160/12500 (97%)]	Loss: 1.113077
2023-12-07 14:14:37,728	base	INFO	[0.04795020818710327, 1.0651271343231201, 9330, 0.0007470712449717098]
2023-12-07 14:14:53,996	base	INFO	Train Epoch: 6 [12320/12500 (99%)]	Loss: 1.105535
2023-12-07 14:14:53,997	base	INFO	[0.05164003372192383, 1.053895354270935, 9350, 0.0007462719816157008]
2023-12-07 14:15:09,960	base	INFO	Train Epoch: 6 [12480/12500 (100%)]	Loss: 1.025348
2023-12-07 14:15:09,962	base	INFO	[0.04686558246612549, 0.9784824252128601, 9370, 0.0007454752780880345]
2023-12-07 14:15:11,155	base	INFO	====> Epoch: 6
2023-12-07 14:15:11,733	base	INFO	Eval Epoch: 6 [0/100 (0%)]	Loss: 1.106567
2023-12-07 14:15:11,733	base	INFO	[0.05061018466949463, 1.0559567213058472]
2023-12-07 14:15:14,600	base	INFO	====> Epoch: 6
2023-12-07 14:15:14,601	base	INFO	Saving model and optimizer state at iteration 6 to ./logs/base/G_6.pdparams
2023-12-07 14:15:17,119	base	INFO	Train Epoch: 7 [0/12500 (0%)]	Loss: 1.078849
2023-12-07 14:15:17,119	base	INFO	[0.06517279148101807, 1.0136765241622925, 9372, 0.0007453957479999981]
2023-12-07 14:15:33,362	base	INFO	Train Epoch: 7 [160/12500 (1%)]	Loss: 1.160154
2023-12-07 14:15:33,369	base	INFO	[0.05453580617904663, 1.1056183576583862, 9392, 0.0007446018445390282]
2023-12-07 14:15:49,182	base	INFO	Train Epoch: 7 [320/12500 (3%)]	Loss: 1.032006
2023-12-07 14:15:49,192	base	INFO	[0.04293501377105713, 0.9890713691711426, 9412, 0.000743810472390106]
2023-12-07 14:16:05,408	base	INFO	Train Epoch: 7 [480/12500 (4%)]	Loss: 1.111822
2023-12-07 14:16:05,410	base	INFO	[0.07141411304473877, 1.040407657623291, 9432, 0.0007430216181302083]
2023-12-07 14:16:21,363	base	INFO	Train Epoch: 7 [640/12500 (5%)]	Loss: 1.135944
2023-12-07 14:16:21,371	base	INFO	[0.06973159313201904, 1.06621253490448, 9452, 0.0007422352684357524]
2023-12-07 14:16:38,056	base	INFO	Train Epoch: 7 [800/12500 (6%)]	Loss: 1.044652
2023-12-07 14:16:38,065	base	INFO	[0.04113030433654785, 1.0035221576690674, 9472, 0.0007414514100816506]
2023-12-07 14:16:54,273	base	INFO	Train Epoch: 7 [960/12500 (8%)]	Loss: 1.027717
2023-12-07 14:16:54,281	base	INFO	[0.047067999839782715, 0.9806492328643799, 9492, 0.0007406700299403766]
2023-12-07 14:17:10,193	base	INFO	Train Epoch: 7 [1120/12500 (9%)]	Loss: 1.026461
2023-12-07 14:17:10,195	base	INFO	[0.058051228523254395, 0.9684093594551086, 9512, 0.0007398911149810414]
2023-12-07 14:17:26,537	base	INFO	Train Epoch: 7 [1280/12500 (10%)]	Loss: 1.121505
2023-12-07 14:17:26,538	base	INFO	[0.05553394556045532, 1.0659714937210083, 9532, 0.0007391146522684813]
2023-12-07 14:17:43,193	base	INFO	Train Epoch: 7 [1440/12500 (12%)]	Loss: 1.097156
2023-12-07 14:17:43,195	base	INFO	[0.05352288484573364, 1.0436334609985352, 9552, 0.0007383406289623552]
2023-12-07 14:17:59,586	base	INFO	Train Epoch: 7 [1600/12500 (13%)]	Loss: 1.039790
2023-12-07 14:17:59,589	base	INFO	[0.042132794857025146, 0.9976569414138794, 9572, 0.0007375690323162528]
2023-12-07 14:18:15,724	base	INFO	Train Epoch: 7 [1760/12500 (14%)]	Loss: 1.059215
2023-12-07 14:18:15,732	base	INFO	[0.04004925489425659, 1.019165277481079, 9592, 0.0007367998496768132]
2023-12-07 14:18:31,721	base	INFO	Train Epoch: 7 [1920/12500 (15%)]	Loss: 1.064823
2023-12-07 14:18:31,723	base	INFO	[0.05521667003631592, 1.009606122970581, 9612, 0.000736033068482853]
2023-12-07 14:18:49,028	base	INFO	Train Epoch: 7 [2080/12500 (17%)]	Loss: 1.070472
2023-12-07 14:18:49,033	base	INFO	[0.04456537961959839, 1.0259060859680176, 9632, 0.0007352686762645054]
2023-12-07 14:19:05,537	base	INFO	Train Epoch: 7 [2240/12500 (18%)]	Loss: 1.093547
2023-12-07 14:19:05,539	base	INFO	[0.04897928237915039, 1.0445672273635864, 9652, 0.0007345066606423675]
2023-12-07 14:19:21,809	base	INFO	Train Epoch: 7 [2400/12500 (19%)]	Loss: 1.033211
2023-12-07 14:19:21,813	base	INFO	[0.04741483926773071, 0.9857962727546692, 9672, 0.0007337470093266594]
2023-12-07 14:19:37,397	base	INFO	Train Epoch: 7 [2560/12500 (20%)]	Loss: 1.146824
2023-12-07 14:19:37,404	base	INFO	[0.06269049644470215, 1.0841333866119385, 9692, 0.0007329897101163908]
2023-12-07 14:19:53,192	base	INFO	Train Epoch: 7 [2720/12500 (22%)]	Loss: 1.140393
2023-12-07 14:19:53,200	base	INFO	[0.04585796594619751, 1.0945347547531128, 9712, 0.0007322347508985378]
2023-12-07 14:20:09,667	base	INFO	Train Epoch: 7 [2880/12500 (23%)]	Loss: 1.095251
2023-12-07 14:20:09,668	base	INFO	[0.05465441942214966, 1.040596842765808, 9732, 0.0007314821196472305]
2023-12-07 14:20:25,924	base	INFO	Train Epoch: 7 [3040/12500 (24%)]	Loss: 1.095452
2023-12-07 14:20:25,927	base	INFO	[0.048818230628967285, 1.0466337203979492, 9752, 0.0007307318044229466]
2023-12-07 14:20:42,840	base	INFO	Train Epoch: 7 [3200/12500 (26%)]	Loss: 1.101475
2023-12-07 14:20:42,843	base	INFO	[0.0623621940612793, 1.039113163948059, 9772, 0.0007299837933717176]
2023-12-07 14:20:58,806	base	INFO	Train Epoch: 7 [3360/12500 (27%)]	Loss: 1.043239
2023-12-07 14:20:58,808	base	INFO	[0.05866914987564087, 0.9845694899559021, 9792, 0.0007292380747243408]
2023-12-07 14:21:14,829	base	INFO	Train Epoch: 7 [3520/12500 (28%)]	Loss: 0.990042
2023-12-07 14:21:14,831	base	INFO	[0.05324894189834595, 0.9367934465408325, 9812, 0.0007284946367956022]
2023-12-07 14:21:31,491	base	INFO	Train Epoch: 7 [3680/12500 (29%)]	Loss: 1.062803
2023-12-07 14:21:31,495	base	INFO	[0.05234569311141968, 1.0104575157165527, 9832, 0.000727753467983508]
2023-12-07 14:21:47,417	base	INFO	Train Epoch: 7 [3840/12500 (31%)]	Loss: 1.093610
2023-12-07 14:21:47,420	base	INFO	[0.06041675806045532, 1.0331933498382568, 9852, 0.0007270145567685229]
2023-12-07 14:22:03,094	base	INFO	Train Epoch: 7 [4000/12500 (32%)]	Loss: 0.970666
2023-12-07 14:22:03,098	base	INFO	[0.07436692714691162, 0.8962987065315247, 9872, 0.0007262778917128193]
2023-12-07 14:22:19,185	base	INFO	Train Epoch: 7 [4160/12500 (33%)]	Loss: 0.997361
2023-12-07 14:22:19,194	base	INFO	[0.05149263143539429, 0.9458683729171753, 9892, 0.0007255434614595325]
2023-12-07 14:22:35,511	base	INFO	Train Epoch: 7 [4320/12500 (35%)]	Loss: 1.017763
2023-12-07 14:22:35,517	base	INFO	[0.05565345287322998, 0.9621095657348633, 9912, 0.0007248112547320266]
2023-12-07 14:22:53,219	base	INFO	Train Epoch: 7 [4480/12500 (36%)]	Loss: 1.099221
2023-12-07 14:22:53,222	base	INFO	[0.045483529567718506, 1.0537372827529907, 9932, 0.0007240812603331664]
2023-12-07 14:23:09,406	base	INFO	Train Epoch: 7 [4640/12500 (37%)]	Loss: 1.044943
2023-12-07 14:23:09,408	base	INFO	[0.05398142337799072, 0.9909617900848389, 9952, 0.0007233534671445985]
2023-12-07 14:23:25,828	base	INFO	Train Epoch: 7 [4800/12500 (38%)]	Loss: 1.136688
2023-12-07 14:23:25,828	base	INFO	[0.051599860191345215, 1.0850882530212402, 9972, 0.0007226278641260401]
2023-12-07 14:23:41,790	base	INFO	Train Epoch: 7 [4960/12500 (40%)]	Loss: 1.055501
2023-12-07 14:23:41,793	base	INFO	[0.05880481004714966, 0.9966963529586792, 9992, 0.0007219044403145757]
2023-12-07 14:23:58,032	base	INFO	Train Epoch: 7 [5120/12500 (41%)]	Loss: 1.091231
2023-12-07 14:23:58,034	base	INFO	[0.044038593769073486, 1.0471928119659424, 10012, 0.0007211831848239608]
2023-12-07 14:24:13,779	base	INFO	Train Epoch: 7 [5280/12500 (42%)]	Loss: 1.053730
2023-12-07 14:24:13,781	base	INFO	[0.03689432144165039, 1.0168359279632568, 10032, 0.0007204640868439349]
2023-12-07 14:24:29,997	base	INFO	Train Epoch: 7 [5440/12500 (44%)]	Loss: 1.128461
2023-12-07 14:24:30,006	base	INFO	[0.04119455814361572, 1.0872666835784912, 10052, 0.0007197471356395398]
2023-12-07 14:24:46,924	base	INFO	Train Epoch: 7 [5600/12500 (45%)]	Loss: 1.035043
2023-12-07 14:24:46,934	base	INFO	[0.027637064456939697, 1.00740647315979, 10072, 0.0007190323205504477]
2023-12-07 14:25:03,240	base	INFO	Train Epoch: 7 [5760/12500 (46%)]	Loss: 1.001065
2023-12-07 14:25:03,249	base	INFO	[0.03946739435195923, 0.9615978002548218, 10092, 0.0007183196309902942]
2023-12-07 14:25:19,286	base	INFO	Train Epoch: 7 [5920/12500 (47%)]	Loss: 1.045102
2023-12-07 14:25:19,295	base	INFO	[0.045867860317230225, 0.9992344975471497, 10112, 0.0007176090564460214]
2023-12-07 14:25:35,789	base	INFO	Train Epoch: 7 [6080/12500 (49%)]	Loss: 1.092031
2023-12-07 14:25:35,792	base	INFO	[0.05434155464172363, 1.037688970565796, 10132, 0.0007169005864772247]
2023-12-07 14:25:52,003	base	INFO	Train Epoch: 7 [6240/12500 (50%)]	Loss: 1.035670
2023-12-07 14:25:52,005	base	INFO	[0.05138117074966431, 0.9842886924743652, 10152, 0.0007161942107155098]
2023-12-07 14:26:08,397	base	INFO	Train Epoch: 7 [6400/12500 (51%)]	Loss: 1.026625
2023-12-07 14:26:08,399	base	INFO	[0.05418968200683594, 0.9724357724189758, 10172, 0.0007154899188638553]
2023-12-07 14:26:24,678	base	INFO	Train Epoch: 7 [6560/12500 (52%)]	Loss: 1.055881
2023-12-07 14:26:24,681	base	INFO	[0.0597345232963562, 0.996146023273468, 10192, 0.0007147877006959815]
2023-12-07 14:26:40,889	base	INFO	Train Epoch: 7 [6720/12500 (54%)]	Loss: 1.013150
2023-12-07 14:26:40,893	base	INFO	[0.060593247413635254, 0.9525572657585144, 10212, 0.0007140875460557276]
2023-12-07 14:26:58,082	base	INFO	Train Epoch: 7 [6880/12500 (55%)]	Loss: 1.098133
2023-12-07 14:26:58,092	base	INFO	[0.044261634349823, 1.0538710355758667, 10232, 0.000713389444856434]
2023-12-07 14:27:13,848	base	INFO	Train Epoch: 7 [7040/12500 (56%)]	Loss: 1.042368
2023-12-07 14:27:13,856	base	INFO	[0.04810130596160889, 0.9942671060562134, 10252, 0.0007126933870803328]
2023-12-07 14:27:30,246	base	INFO	Train Epoch: 7 [7200/12500 (58%)]	Loss: 1.153516
2023-12-07 14:27:30,257	base	INFO	[0.031125903129577637, 1.1223900318145752, 10272, 0.0007119993627779434]
2023-12-07 14:27:46,611	base	INFO	Train Epoch: 7 [7360/12500 (59%)]	Loss: 1.135610
2023-12-07 14:27:46,613	base	INFO	[0.051604270935058594, 1.0840061902999878, 10292, 0.0007113073620674753]
2023-12-07 14:28:03,087	base	INFO	Train Epoch: 7 [7520/12500 (60%)]	Loss: 1.080556
2023-12-07 14:28:03,097	base	INFO	[0.0382080078125, 1.04234778881073, 10312, 0.0007106173751342372]
2023-12-07 14:28:19,633	base	INFO	Train Epoch: 7 [7680/12500 (61%)]	Loss: 1.017732
2023-12-07 14:28:19,635	base	INFO	[0.04520505666732788, 0.9725269675254822, 10332, 0.0007099293922300527]
2023-12-07 14:28:36,513	base	INFO	Train Epoch: 7 [7840/12500 (63%)]	Loss: 1.074131
2023-12-07 14:28:36,515	base	INFO	[0.05620419979095459, 1.0179272890090942, 10352, 0.000709243403672681]
2023-12-07 14:28:53,871	base	INFO	Train Epoch: 7 [8000/12500 (64%)]	Loss: 1.084317
2023-12-07 14:28:53,873	base	INFO	[0.05867093801498413, 1.025646448135376, 10372, 0.0007085593998452456]
2023-12-07 14:29:09,670	base	INFO	Train Epoch: 7 [8160/12500 (65%)]	Loss: 1.092252
2023-12-07 14:29:09,673	base	INFO	[0.042347848415374756, 1.0499043464660645, 10392, 0.0007078773711956672]
2023-12-07 14:29:25,927	base	INFO	Train Epoch: 7 [8320/12500 (67%)]	Loss: 1.048895
2023-12-07 14:29:25,930	base	INFO	[0.04272019863128662, 1.006174921989441, 10412, 0.0007071973082361038]
2023-12-07 14:29:42,146	base	INFO	Train Epoch: 7 [8480/12500 (68%)]	Loss: 1.027329
2023-12-07 14:29:42,148	base	INFO	[0.041380345821380615, 0.9859490990638733, 10432, 0.0007065192015423964]
2023-12-07 14:29:58,397	base	INFO	Train Epoch: 7 [8640/12500 (69%)]	Loss: 1.005679
2023-12-07 14:29:58,407	base	INFO	[0.059414446353912354, 0.9462642669677734, 10452, 0.0007058430417535209]
2023-12-07 14:30:14,115	base	INFO	Train Epoch: 7 [8800/12500 (70%)]	Loss: 1.085683
2023-12-07 14:30:14,124	base	INFO	[0.05242437124252319, 1.0332589149475098, 10472, 0.0007051688195710441]
2023-12-07 14:30:29,998	base	INFO	Train Epoch: 7 [8960/12500 (72%)]	Loss: 1.119322
2023-12-07 14:30:30,006	base	INFO	[0.054312825202941895, 1.0650087594985962, 10492, 0.000704496525758588]
2023-12-07 14:30:45,911	base	INFO	Train Epoch: 7 [9120/12500 (73%)]	Loss: 1.081746
2023-12-07 14:30:45,921	base	INFO	[0.05374467372894287, 1.028000831604004, 10512, 0.0007038261511412972]
2023-12-07 14:31:03,360	base	INFO	Train Epoch: 7 [9280/12500 (74%)]	Loss: 1.080118
2023-12-07 14:31:03,362	base	INFO	[0.057768046855926514, 1.0223499536514282, 10532, 0.0007031576866053141]
2023-12-07 14:31:19,256	base	INFO	Train Epoch: 7 [9440/12500 (76%)]	Loss: 1.017376
2023-12-07 14:31:19,259	base	INFO	[0.03982633352279663, 0.9775499105453491, 10552, 0.0007024911230972577]
2023-12-07 14:31:35,412	base	INFO	Train Epoch: 7 [9600/12500 (77%)]	Loss: 1.110565
2023-12-07 14:31:35,415	base	INFO	[0.044840097427368164, 1.0657247304916382, 10572, 0.000701826451623709]
2023-12-07 14:31:51,507	base	INFO	Train Epoch: 7 [9760/12500 (78%)]	Loss: 1.120282
2023-12-07 14:31:51,510	base	INFO	[0.04735058546066284, 1.0729310512542725, 10592, 0.0007011636632507011]
2023-12-07 14:32:07,793	base	INFO	Train Epoch: 7 [9920/12500 (79%)]	Loss: 0.990111
2023-12-07 14:32:07,796	base	INFO	[0.052117884159088135, 0.937993049621582, 10612, 0.0007005027491032151]
2023-12-07 14:32:23,576	base	INFO	Train Epoch: 7 [10080/12500 (81%)]	Loss: 1.062560
2023-12-07 14:32:23,580	base	INFO	[0.045169293880462646, 1.0173910856246948, 10632, 0.0006998437003646809]
